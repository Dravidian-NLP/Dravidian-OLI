{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DistilmBERT cased",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adeepH/DravidianOffensive/blob/main/Notebooks/Transliterated/Tamil/DistilmBERT_cased.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp9ne18LI0ZD",
        "outputId": "95f202ee-daf2-405c-b548-6c2fa7dcde05"
      },
      "source": [
        "!pip install transformers==3.3.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3.3.1 in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (20.9)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (0.8.1rc2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (0.1.95)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.1) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGoQZFFYJlu8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "ugWqH7iskbgF",
        "outputId": "ba6ee9eb-9884-4d67-80a1-aff4ceecef93"
      },
      "source": [
        "train=pd.read_csv('/content/Trans_tam_train.csv')\n",
        "train['labels']=LabelEncoder().fit_transform(train['label'])\n",
        "train['tweets']=train['transliterated']\n",
        "for i in range(len(train)):\n",
        "  train['tweets'][i]=train['tweets'][i][8:-2]\n",
        "train=train.drop(columns=['label','Unnamed: 0','transliterated','Sentence'])\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>роорпЛро╡ро┐ ро╡рпЗро▒ ро▓ро┐ро╡ро▓рпН ро▓ро╛ роОро░ро┐роХро╛ рокрпКроХрпБродрпБ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>роРро╕рпН ро▓рпЛро╡рпН роЕроЬро┐родрпН роХрпБрооро╛ро░рпН ро╡ро┐ро╡рпЗроХроорпН роорпЛро╡ро┐ роЗроЩрпНроХро┐ роорпЗроЬро┐ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>рокроЯроорпН роиро▓рпНро▓ роХро╛роорпЖроЯро┐ рокроЯро╛роо роЗро░рпБроХрпБроорпН рокрпЛро▓рпИ..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>роХро╛ро░рпНродрпНродро┐роХрпН роЪрпБрокрпНрокро░ро╛роЬрпН роЕройрпНройро┐ .... роЗроирпНрод рокроЯроорпН ро╡рпЖро▒рпН...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>роХро╡рпБрогрпНроЯро░рпН родрпЗро╡ро░рпН.роЪро╛ро░рпНрокро╛роХ ро╡рпЖро▒рпНро▒ро┐ рокрпЖро▒ ро╡ро╛ро┤рпНродрпНродрпБроХрпНроХро│рпН ЁЯжБ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35134</th>\n",
              "      <td>0</td>\n",
              "      <td>роЯро┐ро░ро╛рогрпНроЯро┐роЩрпН роироорпНрокро░рпН #2 роЗродрпБроХрпНроХрпБ роироорпНрооро▓роорпН роХро╛ро░рогроорпНроирпБ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35135</th>\n",
              "      <td>0</td>\n",
              "      <td>роорпЛро╡ро┐ ро╕рпНроХро┐ро░ро┐рокрпНроЯрпН роЪрпВрокрпНрокро░рпН, роЕродрпБро╡рпБроорпН ро╣ро┐рокрпН ро╣ро╛рокрпН родрооро┐...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35136</th>\n",
              "      <td>0</td>\n",
              "      <td>роЬро╕рпНроЯрпН 3роХро┐ ро▓ро┐роХрпНро╕рпН рокрпЛро░рпН 300роХро┐ ро▓ро┐роХрпНро╕рпН</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35137</th>\n",
              "      <td>5</td>\n",
              "      <td>роЖро▓рпЛ ро▓рпЗ ро▓рпЛ. роХрогрпНроЯро╛ ро▓рпЗ ро▓рпЛ.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35138</th>\n",
              "      <td>0</td>\n",
              "      <td>роиро╛роороХрпНроХро▓рпН рооро╛ро╡роЯрпНроЯроорпН ро╡ройрпНройро┐ропро░рпН роЪро╛ро░рпНрокро╛роХ родро┐ро░рпМрокродро┐ рокроЯроо...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35139 rows ├Ч 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       labels                                             tweets\n",
              "0           0                     роорпЛро╡ро┐ ро╡рпЗро▒ ро▓ро┐ро╡ро▓рпН ро▓ро╛ роОро░ро┐роХро╛ рокрпКроХрпБродрпБ\n",
              "1           5  роРро╕рпН ро▓рпЛро╡рпН роЕроЬро┐родрпН роХрпБрооро╛ро░рпН ро╡ро┐ро╡рпЗроХроорпН роорпЛро╡ро┐ роЗроЩрпНроХро┐ роорпЗроЬро┐ ...\n",
              "2           0               рокроЯроорпН роиро▓рпНро▓ роХро╛роорпЖроЯро┐ рокроЯро╛роо роЗро░рпБроХрпБроорпН рокрпЛро▓рпИ..\n",
              "3           0  роХро╛ро░рпНродрпНродро┐роХрпН роЪрпБрокрпНрокро░ро╛роЬрпН роЕройрпНройро┐ .... роЗроирпНрод рокроЯроорпН ро╡рпЖро▒рпН...\n",
              "4           0  роХро╡рпБрогрпНроЯро░рпН родрпЗро╡ро░рпН.роЪро╛ро░рпНрокро╛роХ ро╡рпЖро▒рпНро▒ро┐ рокрпЖро▒ ро╡ро╛ро┤рпНродрпНродрпБроХрпНроХро│рпН ЁЯжБ\n",
              "...       ...                                                ...\n",
              "35134       0  роЯро┐ро░ро╛рогрпНроЯро┐роЩрпН роироорпНрокро░рпН #2 роЗродрпБроХрпНроХрпБ роироорпНрооро▓роорпН роХро╛ро░рогроорпНроирпБ ...\n",
              "35135       0  роорпЛро╡ро┐ ро╕рпНроХро┐ро░ро┐рокрпНроЯрпН роЪрпВрокрпНрокро░рпН, роЕродрпБро╡рпБроорпН ро╣ро┐рокрпН ро╣ро╛рокрпН родрооро┐...\n",
              "35136       0                 роЬро╕рпНроЯрпН 3роХро┐ ро▓ро┐роХрпНро╕рпН рокрпЛро░рпН 300роХро┐ ро▓ро┐роХрпНро╕рпН\n",
              "35137       5                            роЖро▓рпЛ ро▓рпЗ ро▓рпЛ. роХрогрпНроЯро╛ ро▓рпЗ ро▓рпЛ.\n",
              "35138       0  роиро╛роороХрпНроХро▓рпН рооро╛ро╡роЯрпНроЯроорпН ро╡ройрпНройро┐ропро░рпН роЪро╛ро░рпНрокро╛роХ родро┐ро░рпМрокродро┐ рокроЯроо...\n",
              "\n",
              "[35139 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "Whp4CHwJOr8H",
        "outputId": "56bf1a7c-9529-4990-eeda-69a40239fc80"
      },
      "source": [
        "val=pd.read_csv('/content/Trans_tam_test.csv')\n",
        "val['labels']=LabelEncoder().fit_transform(val['label'])\n",
        "val['tweets']=val['transliterated']\n",
        "for i in range(len(val)):\n",
        "  val['tweets'][i]=val['tweets'][i][8:-2]\n",
        "val=val.drop(columns=['label','Unnamed: 0','transliterated','Sentence'])\n",
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>14.12.2018 роОрокрпЛ роЯро┐ро░рпИро▓ро░рпН рокродрпБродрпБ роЗро░рпНроХро┐ройрпН ... роЪрпЗрооро╛роп...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>рокро╛роХро╛ родро╛рой рокрпЛро░рпЛ роорпЛро╡ро┐ ро▓ро╛ роОрогрпНрогро╛ роЗро░рпБроХрпБрогрпБрогрпБ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>тАЬропрпВ роХрпЗройро╛ родрпБроЩрпНроХрпБ ро▓рпЖрокро┐ ро▓ро╛рооро╛ ро▓ро╛роХро┐ роЙрогрпНроЯрпБроХрпН родро╡рпБ роЪро╛роп...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>роЪрпВро░ро┐роп роЕройрпНрой ро╡рпЗро▒ ро▓ро┐ро╡ро▓рпН роЕройрпНрой рооро╛ро╕рпН</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>роЪрпВрооро╛ роХродрпНродро╛род роЯро╛ роЪро╡рпБрогрпНроЯрпН роУро╡ро░рпН роЕроорпН рокрпВроЯро╛ роХрпБроЯро╛родрпБ рокро╛...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4387</th>\n",
              "      <td>1</td>\n",
              "      <td>роорогрпНрогрпБ рокрпКрогрпНрогрпБ ро░рпЖрогрпНроЯрпБроорпЗ роТройрпНройрпБ роЕродрпБро▓ роОро╡ройрпН роХрпИроп ро╡роЪрпНроЪ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4388</th>\n",
              "      <td>5</td>\n",
              "      <td>рокро╛рокрпБ роорпЗро▓рпН роХрпЛ роРро╕рпН роЪро╛роЩрпН роЪрпБройрпНрокрпЗ роХрпБроЪрпН роОро╖ро╛ рокрпАро▓рпН ро╣рпВро╡...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4389</th>\n",
              "      <td>0</td>\n",
              "      <td>роЕроЪрпБро░ро╛ройрпН= роЖроЯрпБроХро▓роорпН+рокрпБроЯрпБрокрпЖроЯрпНроЯрпИ+ ро╡ро╛родро╛ роЪрпЖройрпНройрпИ..роОро▓рпНро▓...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4390</th>\n",
              "      <td>0</td>\n",
              "      <td>ро╡ро┐роЬропрпН'ро╕рпН роЖро▓рпН роорпЛро╡ро┐ро╕рпН ро▓рпЛроХрпН ро▓ро┐роХрпН роЪрпЗроорпН.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4391</th>\n",
              "      <td>1</td>\n",
              "      <td>роП роЗродрпБ 96, ропро╛ро░ роОроородрпБро░ро┐роЩрпНроХ.. рокроЩрпНроХроорпН роЬрпА рокроЩрпНроХроорпН роЬрпА</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4392 rows ├Ч 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      labels                                             tweets\n",
              "0          0  14.12.2018 роОрокрпЛ роЯро┐ро░рпИро▓ро░рпН рокродрпБродрпБ роЗро░рпНроХро┐ройрпН ... роЪрпЗрооро╛роп...\n",
              "1          0              рокро╛роХро╛ родро╛рой рокрпЛро░рпЛ роорпЛро╡ро┐ ро▓ро╛ роОрогрпНрогро╛ роЗро░рпБроХрпБрогрпБрогрпБ\n",
              "2          5  тАЬропрпВ роХрпЗройро╛ родрпБроЩрпНроХрпБ ро▓рпЖрокро┐ ро▓ро╛рооро╛ ро▓ро╛роХро┐ роЙрогрпНроЯрпБроХрпН родро╡рпБ роЪро╛роп...\n",
              "3          0                     роЪрпВро░ро┐роп роЕройрпНрой ро╡рпЗро▒ ро▓ро┐ро╡ро▓рпН роЕройрпНрой рооро╛ро╕рпН\n",
              "4          4  роЪрпВрооро╛ роХродрпНродро╛род роЯро╛ роЪро╡рпБрогрпНроЯрпН роУро╡ро░рпН роЕроорпН рокрпВроЯро╛ роХрпБроЯро╛родрпБ рокро╛...\n",
              "...      ...                                                ...\n",
              "4387       1  роорогрпНрогрпБ рокрпКрогрпНрогрпБ ро░рпЖрогрпНроЯрпБроорпЗ роТройрпНройрпБ роЕродрпБро▓ роОро╡ройрпН роХрпИроп ро╡роЪрпНроЪ...\n",
              "4388       5  рокро╛рокрпБ роорпЗро▓рпН роХрпЛ роРро╕рпН роЪро╛роЩрпН роЪрпБройрпНрокрпЗ роХрпБроЪрпН роОро╖ро╛ рокрпАро▓рпН ро╣рпВро╡...\n",
              "4389       0  роЕроЪрпБро░ро╛ройрпН= роЖроЯрпБроХро▓роорпН+рокрпБроЯрпБрокрпЖроЯрпНроЯрпИ+ ро╡ро╛родро╛ роЪрпЖройрпНройрпИ..роОро▓рпНро▓...\n",
              "4390       0                ро╡ро┐роЬропрпН'ро╕рпН роЖро▓рпН роорпЛро╡ро┐ро╕рпН ро▓рпЛроХрпН ро▓ро┐роХрпН роЪрпЗроорпН.\n",
              "4391       1      роП роЗродрпБ 96, ропро╛ро░ роОроородрпБро░ро┐роЩрпНроХ.. рокроЩрпНроХроорпН роЬрпА рокроЩрпНроХроорпН роЬрпА\n",
              "\n",
              "[4392 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMd3ZHtlPpLv"
      },
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class RFDataset(Dataset):\n",
        "  def __init__(self,tweets,labels,tokenizer,max_len):\n",
        "    self.tweets = tweets\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.tweets)\n",
        "  \n",
        "  def __getitem__(self,item):\n",
        "    tweets = str(self.tweets[item])\n",
        "    labels = self.labels[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        tweets,\n",
        "        add_special_tokens=True,\n",
        "        max_length = self.max_len,\n",
        "        return_token_type_ids = False,\n",
        "        padding = 'max_length',\n",
        "        return_attention_mask= True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'tweets' : tweets,\n",
        "        'input_ids' : encoding['input_ids'].flatten(),\n",
        "        'attention_mask' : encoding['attention_mask'].flatten(),\n",
        "        'labels' : torch.tensor(labels,dtype=torch.long)\n",
        "\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDdVdA1bQlUF",
        "outputId": "8bf8063d-65ce-4f63-ab8e-84c95c0595ea"
      },
      "source": [
        " \n",
        "print('Training set size:',train.shape)\n",
        "#Uncomment the next line when we have the test data\n",
        "#print('Testing set size:',test.shape)\n",
        "print('validation set size:',val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size: (35139, 2)\n",
            "validation set size: (4392, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFA6pybHQwOX",
        "outputId": "744abafb-6892-42f8-8002-dc986766f22a"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                  np.unique(train.labels.values),\n",
        "                                                  train.labels.values)\n",
        "class_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.23034415,  2.29037935,  2.4995732 , 12.89977974,  2.01531315,\n",
              "        4.0278542 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrS3mf4RQyy9"
      },
      "source": [
        "def create_data_loader(df,tokenizer,max_len,batch_size):\n",
        "  ds = RFDataset(\n",
        "      tweets = df.tweets.to_numpy(),\n",
        "      labels = df.labels.to_numpy(),\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(ds,\n",
        "                    batch_size = batch_size,\n",
        "                    shuffle = True,\n",
        "                    num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5HC7hmTQ1zg"
      },
      "source": [
        "from transformers import XLNetTokenizer,XLNetModel,AdamW,get_linear_schedule_with_warmup,AutoModel,AutoTokenizer\n",
        "device = 'cuda'\n",
        "PRE_TRAINED_MODEL_NAME = 'distilbert-base-multilingual-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_c7oQlUQ4ED",
        "outputId": "3b080e9c-cc54-47c4-a763-fb4e4f8db3d7"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 512\n",
        "train_data_loader = create_data_loader(train,tokenizer,MAX_LEN,BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(val,tokenizer,MAX_LEN,BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkIQTq3Q6-b"
      },
      "source": [
        "BERT_model = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELD76HMVQ9HQ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class DistillBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistillBERTClass, self).__init__()\n",
        "        self.l1 = AutoModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 6)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzOmQqNyRAqg"
      },
      "source": [
        "\n",
        "model = DistillBERTClass()\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxxmEAKvRC5H"
      },
      "source": [
        "EPOCHS = 5\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x444fs7R0oz"
      },
      "source": [
        "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        input_ids = data['input_ids'].to(device)\n",
        "        attention_mask = data['attention_mask'].to(device)\n",
        "        labels = data['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "            )\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs,labels)\n",
        "\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGTlOJP3R2rX"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"labels\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      correct_predictions += torch.sum(preds == labels)\n",
        "      losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvBZLbZAR4wN"
      },
      "source": [
        "\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN5SVoUVR6kL",
        "outputId": "798360fc-e532-4cc6-b038-04451304fc61"
      },
      "source": [
        "from collections import defaultdict\n",
        "import torch\n",
        " \n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        " \n",
        " \n",
        "  start_time = time.time()\n",
        "  train_acc,train_loss = train_epoch(\n",
        "      model,\n",
        "      train_data_loader,\n",
        "      loss_fn,\n",
        "      optimizer,\n",
        "      device,\n",
        "      scheduler,\n",
        "      len(train)\n",
        "  )\n",
        "   \n",
        " \n",
        "  val_acc,val_loss = eval_model(\n",
        "      model,\n",
        "      val_data_loader,\n",
        "      loss_fn,\n",
        "      device,\n",
        "      len(val)\n",
        "  )\n",
        "\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'Train Loss {train_loss} accuracy {train_acc}')\n",
        "  print(f'Val Loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if train_acc > best_accuracy:\n",
        "     \n",
        "    best_accuracy = train_acc\n",
        "torch.save(model.state_dict(),'distilbert-base-multilingual-cased.bin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 30m 50s\n",
            "Train Loss 0.8172606431832897 accuracy 0.7378126867583027\n",
            "Val Loss 0.7611582587320697 accuracy 0.7566029143897997\n",
            "\n",
            "Epoch: 02 | Epoch Time: 30m 55s\n",
            "Train Loss 0.676569781047841 accuracy 0.7677793904208998\n",
            "Val Loss 0.7055504247817126 accuracy 0.7634335154826958\n",
            "\n",
            "Epoch: 03 | Epoch Time: 30m 56s\n",
            "Train Loss 0.599705727374996 accuracy 0.7910299097868465\n",
            "Val Loss 0.7044585534930229 accuracy 0.7607012750455373\n",
            "\n",
            "Epoch: 04 | Epoch Time: 30m 55s\n",
            "Train Loss 0.5265444352083386 accuracy 0.8163863513475056\n",
            "Val Loss 0.7620275327834216 accuracy 0.7668488160291439\n",
            "\n",
            "Epoch: 05 | Epoch Time: 30m 55s\n",
            "Train Loss 0.47453031535474455 accuracy 0.8352827342838441\n",
            "Val Loss 0.7806948697566987 accuracy 0.7570582877959927\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "pXpyt4kPR8Qo",
        "outputId": "077aa378-b78c-4630-ba80-b13459fff572"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4jnJ_DeVChr",
        "outputId": "7c1c7f6c-c3c0-4969-b01d-196c561c7af7"
      },
      "source": [
        "val_acc, _ = eval_model(\n",
        "  model,\n",
        "  val_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(val) #Change it to test when you have the test results\n",
        ")\n",
        "val_acc.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7570582877959927"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WrOtx2a1VFPV"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  sentence = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      tweets = d[\"tweets\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"labels\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      sentence.extend(tweets)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(labels)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return sentence, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2A6ySmh7VNeo",
        "outputId": "bf04c82c-410c-4d56-dd6c-708d87b11d55"
      },
      "source": [
        "\n",
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  val_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdnRltryVRuD"
      },
      "source": [
        "class_name = ['Hope_speech','Non_hope_speech','not-Tamil']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7AbMa4soViJ-",
        "outputId": "f5b9be1e-f1fe-42bc-875b-599008c1cbf7"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test, y_pred,zero_division=0, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8424    0.9132    0.8764      3190\n",
            "           1     0.3054    0.2535    0.2770       288\n",
            "           2     0.3701    0.2984    0.3304       315\n",
            "           3     0.0000    0.0000    0.0000        71\n",
            "           4     0.4422    0.3641    0.3994       368\n",
            "           5     0.8043    0.6937    0.7450       160\n",
            "\n",
            "    accuracy                         0.7571      4392\n",
            "   macro avg     0.4608    0.4205    0.4380      4392\n",
            "weighted avg     0.7248    0.7571    0.7390      4392\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaYOjpfbO84z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}