{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adeepH/DravidianOffensive/blob/main/Notebooks/CM-TRA/Malayalam/muril.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KUITVK6TjLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f4cf936-bfb1-40f8-b311-9c67f8bb2bf1"
      },
      "source": [
        "!pip install transformers "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "706PiOXoTn2E"
      },
      "source": [
        "import re\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification, DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from transformers import AdamW\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import seaborn as sns\n",
        "% matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHT-6u3aUEHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208361db-7c3a-4593-a071-3ee8e626898a"
      },
      "source": [
        "!git clone https://github.com/adeepH/DravidianOffensive.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'DravidianOffensive' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PzpqIBuuJ2y"
      },
      "source": [
        "path = []\n",
        "root_path = '/content/DravidianOffensive/Datasets/'\n",
        "train_ = root_path + 'kannada_offensive_train (1).csv'\n",
        "test_ = root_path + 'kannada_offensive_test_with_labels.csv'\n",
        "val_ = root_path + 'kannada_offensive_dev.csv'\n",
        "path.append(train_)\n",
        "path.append(val_)\n",
        "path.append(test_)\n",
        "def load_files(path):\n",
        "    p = []\n",
        "    for i in range(0,len(path)):\n",
        "        p.append(pd.read_csv(path[i],header=None,names=['tweets','label'],sep=\"\\t\"))\n",
        "        p[i]['labels'] = LabelEncoder().fit_transform(p[i]['label'])\n",
        "        p[i] = p[i].drop(columns='label')\n",
        "    return p[0],p[1],p[2]\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "train, val, test = load_files(path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "6iif05dXRGdi",
        "outputId": "fb2890dd-af07-490c-bf66-6ab03509b799"
      },
      "source": [
        "train=pd.read_csv('/content/DravidianOffensive/Datasets/Pseudo Labels/Pseudo_Mal.csv')\n",
        "train['labels']=LabelEncoder().fit_transform(train['labels']) \n",
        "#for i in range(len(train)):\n",
        "#  train['tweets'][i]=train['tweets'][i][8:-2]\n",
        "train=train.drop(columns=['Unnamed: 0'])\n",
        "train"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്ത...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ഈ ഓണം ഏട്ടനും പിള്ളേർക്ക് ഉള്ളതാണ് എന്ന് ഉള്ളവ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sushin syam  Shaiju khalid  Midhun manual</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J A K E S.   B EJ O Y !!!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38014</th>\n",
              "      <td>{'ml': 'അരുടേയും കാണീർ ഓപ്പൺ വന്നദല്ല ഞൈൻ... !...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38015</th>\n",
              "      <td>{'ml': 'മലയാളം ലേഡി സൂപ്പർ സ്റ്റാർ......അതുക് ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38016</th>\n",
              "      <td>{'ml': 'ഇൻഡ്യൻ സിനിമ ലിവിംഗ് ലെഗഡ് മോളിവുഡ് കി...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38017</th>\n",
              "      <td>{'ml': 'ചെറിയ തെറ്റുകൾ എടുത്തു കളയണം. പിന്നീട്...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38018</th>\n",
              "      <td>{'ml': 'എന്റ് പൊന്നോ..... എടാർ എട്ടം.... ഇത് പ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38019 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweets  labels\n",
              "0      പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്ത...       0\n",
              "1      ഈ ഓണം ഏട്ടനും പിള്ളേർക്ക് ഉള്ളതാണ് എന്ന് ഉള്ളവ...       0\n",
              "2      ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്...       0\n",
              "3              Sushin syam  Shaiju khalid  Midhun manual       0\n",
              "4                              J A K E S.   B EJ O Y !!!       0\n",
              "...                                                  ...     ...\n",
              "38014  {'ml': 'അരുടേയും കാണീർ ഓപ്പൺ വന്നദല്ല ഞൈൻ... !...       0\n",
              "38015  {'ml': 'മലയാളം ലേഡി സൂപ്പർ സ്റ്റാർ......അതുക് ...       0\n",
              "38016  {'ml': 'ഇൻഡ്യൻ സിനിമ ലിവിംഗ് ലെഗഡ് മോളിവുഡ് കി...       0\n",
              "38017  {'ml': 'ചെറിയ തെറ്റുകൾ എടുത്തു കളയണം. പിന്നീട്...       0\n",
              "38018  {'ml': 'എന്റ് പൊന്നോ..... എടാർ എട്ടം.... ഇത് പ...       0\n",
              "\n",
              "[38019 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvNNvTaMYcKp",
        "outputId": "a0ae779d-26c5-4492-c1c2-ca34b32aa83f"
      },
      "source": [
        "train.labels.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    35926\n",
              "4     1466\n",
              "2      263\n",
              "3      211\n",
              "1      153\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "w3xc5GdyRIMh",
        "outputId": "8e4c4f7c-f5b0-4c68-e571-600faaa654a0"
      },
      "source": [
        "val=pd.read_csv('/content/DravidianOffensive/Datasets/Trans_mal_test.csv')\n",
        "val['labels']=LabelEncoder().fit_transform(val['label'])\n",
        "val['tweets']=val['Sentence']\n",
        "#for i in range(len(val)):\n",
        "#  val['tweets'][i]=val['tweets'][i][8:-2]\n",
        "val=val.drop(columns=['label','Unnamed: 0','transliterated','Sentence'])\n",
        "val"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>അപ്പൊ ഇതൊരൊന്നൊരാ മൊതലാണല്ലേ  Suraj ആണ് നടൻ ന്...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>എന്ത് ഊള എഡിറ്റിംഗ് ആടോ ഇത് ഒരുമാതിരി vivo vid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Fefka ee padam release cheyyan samadhicho?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>അആഹാ.. സംഗീതം ജെക്‌സ് ബിജോയ് ആണ് അപ്പൊ പൊട്ടലു...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Ravile thane views likes ethra ayyi enn nokan ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>0</td>\n",
              "      <td>Swargatthil ninnu purathaakkappetta daivatthin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>0</td>\n",
              "      <td>Ivide Palakkad Jayettan Fans club nnu ashamsak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>0</td>\n",
              "      <td>ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>0</td>\n",
              "      <td>കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>0</td>\n",
              "      <td>Koora padam urappa kandal aryam.. Hello</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2001 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      labels                                             tweets\n",
              "0          0  അപ്പൊ ഇതൊരൊന്നൊരാ മൊതലാണല്ലേ  Suraj ആണ് നടൻ ന്...\n",
              "1          0  എന്ത് ഊള എഡിറ്റിംഗ് ആടോ ഇത് ഒരുമാതിരി vivo vid...\n",
              "2          0         Fefka ee padam release cheyyan samadhicho?\n",
              "3          0  അആഹാ.. സംഗീതം ജെക്‌സ് ബിജോയ് ആണ് അപ്പൊ പൊട്ടലു...\n",
              "4          0  Ravile thane views likes ethra ayyi enn nokan ...\n",
              "...      ...                                                ...\n",
              "1996       0  Swargatthil ninnu purathaakkappetta daivatthin...\n",
              "1997       0  Ivide Palakkad Jayettan Fans club nnu ashamsak...\n",
              "1998       0      ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും\n",
              "1999       0  കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...\n",
              "2000       0            Koora padam urappa kandal aryam.. Hello\n",
              "\n",
              "[2001 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RSTGy5IY0Pw",
        "outputId": "9eb1f439-2cd6-47e7-c98a-e0687cde8d2f"
      },
      "source": [
        "val.labels.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1765\n",
              "4     157\n",
              "3      29\n",
              "2      27\n",
              "1      23\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHslUWdGU3-j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e3f9d09-3e76-4fdd-bce6-7cf532d63032"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXZ55TLGVSCZ"
      },
      "source": [
        "train_sentences = train['tweets'].values.tolist()\n",
        "val_sentences = val['tweets'].values.tolist()\n",
        "#test_sentences = test['tweets'].values.tolist()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV3icAHvWIBt"
      },
      "source": [
        "def preprocess_texts(sentences):\n",
        "  sentences = [re.sub(r'http\\S+','',s) for s in sentences]\n",
        "  sentences = [s.replace('#','') for s in sentences]\n",
        "  sentences = [s + \" [SEP] [CLS]\" for s in sentences]\n",
        "  return sentences"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpVlYtcnX0Ol"
      },
      "source": [
        "train_sentences = preprocess_texts(train_sentences)\n",
        "val_sentences = preprocess_texts(val_sentences)\n",
        "#test_sentences = preprocess_texts(test_sentences)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gb_nm7SagUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e2e510-0f64-4262-a874-72b7076ab185"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained('google/muril-base-cased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts_train = [tokenizer.tokenize(s) for s in train_sentences]\n",
        "tokenized_texts_val = [tokenizer.tokenize(s) for s in val_sentences]\n",
        "#tokenized_texts_test = [tokenizer.tokenize(s) for s in test_sentences]\n",
        "print (tokenized_texts_train[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['പല', '##ദേശം', '.', 'പല', 'ഭാഷ', 'ഒരേ', 'ഒരു', 'രാജാവ്', 'അല്ലാതെ', 'സ്വന്തം', 'രാജ', '##വ', '##യത്', 'അല്ല', '[SEP]', '[CLS]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6UkrHfOaiZb"
      },
      "source": [
        "train['len'] = [len(s.split()) for s in train['tweets']]\n",
        "val['len'] = [len(s.split()) for s in val['tweets']]\n",
        "#test['len'] = [len(s.split()) for s in test['tweets']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06QcsuBYbYdN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "be08d196-0a93-485f-e179-bd1250d07fa2"
      },
      "source": [
        "plt.figure(figsize=(25,6))\n",
        "sns.countplot(train['len'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc70b0693d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5B4CjQ2bvj7"
      },
      "source": [
        "MAX_LEN = 128\n",
        "input_ids_train = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_train]\n",
        "input_ids_val = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_val]\n",
        "#input_ids_test = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_test]\n",
        "\n",
        "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids_val = pad_sequences(input_ids_val, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "#input_ids_test = pad_sequences(input_ids_test,maxlen=MAX_LEN,dtype=\"long\", truncating=\"post\",padding=\"post\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwqpkSonepVc"
      },
      "source": [
        "\n",
        "attention_masks_train = []\n",
        "attention_masks_val = []\n",
        "attention_masks_test = []\n",
        "for seq in input_ids_train:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks_train.append(seq_mask)\n",
        "\n",
        "for seq in input_ids_val:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks_val.append(seq_mask)\n",
        "\n",
        "#for seq in input_ids_test:\n",
        "#    seq_mask =[float(i>0) for i in seq]\n",
        "#    attention_masks_test.append(seq_mask)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyr5TukkhCxv"
      },
      "source": [
        "train_labels, validation_labels = train['labels'].values.tolist(), val['labels'].values.tolist()#, test['labels'].values.tolist()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWJTMRFKhGBy"
      },
      "source": [
        "train_inputs = torch.tensor(input_ids_train)\n",
        "validation_inputs = torch.tensor(input_ids_val)\n",
        "#test_inputs = torch.tensor(input_ids_test)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "#test_labels = torch.tensor(test_labels)\n",
        "train_masks = torch.tensor(attention_masks_train)\n",
        "validation_masks = torch.tensor(attention_masks_val)\n",
        "#test_masks = torch.tensor(attention_masks_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3akUo498jB39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572c69a8-a169-45a4-aece-a90fb3a22525"
      },
      "source": [
        "train_inputs.shape,validation_inputs.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([38019, 128]), torch.Size([2001, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1dvhu73h7we"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "#test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "#test_sampler = SequentialSampler(test_data)\n",
        "#test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVEbXfFIiV83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c167f1-1d17-44f9-cfc5-0438ad0c8fcc"
      },
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"google/muril-base-cased\", num_labels=5)\n",
        "model.cuda()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(197285, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REni62O3iec3"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahv9xOpIncD9"
      },
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                     lr=5e-4)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86VFLMpLu2Hm"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUVLBfJInfP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f990d3b-53c5-48ad-92bc-8cb33a038872"
      },
      "source": [
        "train_loss_set = []\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  start_time = time.time()\n",
        "  model.train()\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    outputs = model(b_input_ids, \n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask, labels=b_labels)\n",
        "    \n",
        "    loss = outputs[0]\n",
        "    logits = outputs[1]\n",
        "    train_loss_set.append(loss.item())    \n",
        "    \n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "  end_time = time.time()\n",
        "\n",
        "  print(epoch_time(start_time,end_time))\n",
        "\n",
        "  print(\"\\nTrain loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "  #print(\"\\nTrain accuracy : {}\".format(100 * correct / total))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  20%|██        | 1/5 [07:11<28:47, 431.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7, 11)\n",
            "\n",
            "Train loss: 0.2893280106181858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 2/5 [14:23<21:35, 431.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7, 11)\n",
            "\n",
            "Train loss: 0.26687638132261626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 3/5 [21:35<14:23, 431.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7, 12)\n",
            "\n",
            "Train loss: 0.2668424545403789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 4/5 [28:48<07:12, 432.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7, 12)\n",
            "\n",
            "Train loss: 0.2668697254685294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 5/5 [36:00<00:00, 432.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7, 12)\n",
            "\n",
            "Train loss: 0.2666152425486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLgdxLCaodgq"
      },
      "source": [
        "preds = []\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, batch in enumerate(validation_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    outputs = model(b_input_ids, \n",
        "                    #token_type_ids=None, \n",
        "                    attention_mask=b_input_mask)\n",
        "    #print (outputs)\n",
        "    prediction = torch.argmax(outputs[0],dim=1)\n",
        "    preds.append(prediction)\n",
        "    total += b_labels.size(0)\n",
        "    correct+=(prediction==b_labels).sum().item()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsO5j1U3tNQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7941aecf-913f-452e-fc6a-15763db83e58"
      },
      "source": [
        "print('Test Accuracy of the model {} %'.format(100 * correct / total))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model 88.20589705147427 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmvWPYFztdNO"
      },
      "source": [
        "final_preds = []\n",
        "for tensor in preds:\n",
        "  for pred in tensor:\n",
        "    final_preds.append(int(pred))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v1dbm0T_8Dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b932deba-ee63-4b84-8420-cebf6b413dd3"
      },
      "source": [
        "print(classification_report(val['labels'].values.tolist(),final_preds,digits=4))#,target_names=test['labels']))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8821    1.0000    0.9373      1765\n",
            "           1     0.0000    0.0000    0.0000        23\n",
            "           2     0.0000    0.0000    0.0000        27\n",
            "           3     0.0000    0.0000    0.0000        29\n",
            "           4     0.0000    0.0000    0.0000       157\n",
            "\n",
            "    accuracy                         0.8821      2001\n",
            "   macro avg     0.1764    0.2000    0.1875      2001\n",
            "weighted avg     0.7780    0.8821    0.8268      2001\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAtt6KYuAjdN"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}