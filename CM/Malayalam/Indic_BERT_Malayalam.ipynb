{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Indic-BERT-Malayalam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adeepH/DravidianOffensive/blob/main/CM/Malayalam/Indic_BERT_Malayalam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQgS3U09Htd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "309fc8ca-186b-4a32-dc55-89891b3529ab"
      },
      "source": [
        "!pip install transformers==3.3.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 6.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 35.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 54.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (20.9)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/26/c02ba92ecb8b780bdae4a862d351433c2912fe49469dac7f87a5c85ccca6/tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.1) (2.4.7)\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BeHAb-BM9w1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "0aacae33-7a78-48e6-9502-48057c79d9a4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "train=pd.read_csv('/content/mal_full_offensive_train.tsv', header=None, names=['tweets','label'], sep=\"\\t\")\n",
        "train['labels']=LabelEncoder().fit_transform(train['label'])\n",
        "train=train.drop(columns='label')\n",
        "train"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്ത...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ഈ ഓണം ഏട്ടനും പിള്ളേർക്ക് ഉള്ളതാണ് എന്ന് ഉള്ളവ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sushin syam  Shaiju khalid  Midhun manual</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J A K E S.   B EJ O Y !!!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16005</th>\n",
              "      <td>കട്ട ലാലേട്ടൻ ഫാൻസിന് ദൈവത്തെ ഓർത്ത് അമിത പ്രത...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16006</th>\n",
              "      <td>ente mammookka ningal puliyalla oru simhama......</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16007</th>\n",
              "      <td>Lucifer mass dialogues Ellam onnu comment chey...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16008</th>\n",
              "      <td>Like from Madurai (Tamil nadu) ....</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16009</th>\n",
              "      <td>അടിമകൾ ആയി ജീവിച്ചു മാറിക്കയല്ല ചാവേറായി ചാവാറ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16010 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweets  labels\n",
              "0      പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്ത...       0\n",
              "1      ഈ ഓണം ഏട്ടനും പിള്ളേർക്ക് ഉള്ളതാണ് എന്ന് ഉള്ളവ...       0\n",
              "2      ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്...       0\n",
              "3              Sushin syam  Shaiju khalid  Midhun manual       0\n",
              "4                              J A K E S.   B EJ O Y !!!       0\n",
              "...                                                  ...     ...\n",
              "16005  കട്ട ലാലേട്ടൻ ഫാൻസിന് ദൈവത്തെ ഓർത്ത് അമിത പ്രത...       0\n",
              "16006  ente mammookka ningal puliyalla oru simhama......       0\n",
              "16007  Lucifer mass dialogues Ellam onnu comment chey...       0\n",
              "16008                Like from Madurai (Tamil nadu) ....       4\n",
              "16009  അടിമകൾ ആയി ജീവിച്ചു മാറിക്കയല്ല ചാവേറായി ചാവാറ...       0\n",
              "\n",
              "[16010 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoAmYVC5Ldq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "2bda0af1-9eb2-4019-ad78-0a68203fdbfb"
      },
      "source": [
        "val = pd.read_csv('/content/mal_full_offensive_test_with_labels.csv', delimiter='\\t', names=['tweets','label','nan'])\n",
        "val = val.drop(columns=['nan'])\n",
        "val['labels']=LabelEncoder().fit_transform(val['label'])\n",
        "val=val.drop(columns='label')\n",
        "val"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>അപ്പൊ ഇതൊരൊന്നൊരാ മൊതലാണല്ലേ  Suraj ആണ് നടൻ ന്...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>എന്ത് ഊള എഡിറ്റിംഗ് ആടോ ഇത് ഒരുമാതിരി vivo vid...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fefka ee padam release cheyyan samadhicho?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>അആഹാ.. സംഗീതം ജെക്‌സ് ബിജോയ് ആണ് അപ്പൊ പൊട്ടലു...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ravile thane views likes ethra ayyi enn nokan ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>Swargatthil ninnu purathaakkappetta daivatthin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Ivide Palakkad Jayettan Fans club nnu ashamsak...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>Koora padam urappa kandal aryam.. Hello</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2001 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 tweets  labels\n",
              "0     അപ്പൊ ഇതൊരൊന്നൊരാ മൊതലാണല്ലേ  Suraj ആണ് നടൻ ന്...       0\n",
              "1     എന്ത് ഊള എഡിറ്റിംഗ് ആടോ ഇത് ഒരുമാതിരി vivo vid...       0\n",
              "2            Fefka ee padam release cheyyan samadhicho?       0\n",
              "3     അആഹാ.. സംഗീതം ജെക്‌സ് ബിജോയ് ആണ് അപ്പൊ പൊട്ടലു...       0\n",
              "4     Ravile thane views likes ethra ayyi enn nokan ...       0\n",
              "...                                                 ...     ...\n",
              "1996  Swargatthil ninnu purathaakkappetta daivatthin...       0\n",
              "1997  Ivide Palakkad Jayettan Fans club nnu ashamsak...       0\n",
              "1998      ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും       0\n",
              "1999  കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...       0\n",
              "2000            Koora padam urappa kandal aryam.. Hello       0\n",
              "\n",
              "[2001 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS6rIZeEKma6"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class RFDataset(Dataset):\n",
        "  def __init__(self,text,label,tokenizer,max_len):\n",
        "    self.text = text\n",
        "    self.label = label\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "  \n",
        "  def __getitem__(self,item):\n",
        "    text = str(self.text[item])\n",
        "    label = self.label[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length = self.max_len,\n",
        "        return_token_type_ids = False,\n",
        "        padding = 'max_length',\n",
        "        return_attention_mask= True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'text' : text,\n",
        "        'input_ids' : encoding['input_ids'].flatten(),\n",
        "        'attention_mask' : encoding['attention_mask'].flatten(),\n",
        "        'label' : torch.tensor(label,dtype=torch.long)\n",
        "\n",
        "    }"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyLc0LX0M5U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe00aab-e282-421f-fa69-23edc261b317"
      },
      "source": [
        " \n",
        "print('Training set size:',train.shape)\n",
        "#Uncomment the next line when we have the test data\n",
        "#print('Testing set size:',test.shape)\n",
        "print('validation set size:',val.shape)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size: (16010, 2)\n",
            "validation set size: (2001, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBHTeh4rO3Ri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397e446c-0515-40ea-cba2-84bae65a8ab8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                  np.unique(train.labels.values),\n",
        "                                                  train.labels.values)\n",
        "class_weights"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.22624179, 22.87142857, 13.39748954, 16.76439791,  2.48795649])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKS4d5sfRGOu"
      },
      "source": [
        "\n",
        "def create_data_loader(df,tokenizer,max_len,batch_size):\n",
        "  ds = RFDataset(\n",
        "      text = df.tweets.to_numpy(),\n",
        "      label = df.labels.to_numpy(),\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(ds,\n",
        "                    batch_size = batch_size,\n",
        "                    shuffle = True,\n",
        "                    num_workers=4)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwkYcm1PRrGk"
      },
      "source": [
        "from transformers import XLNetTokenizer,XLNetModel,AdamW,get_linear_schedule_with_warmup,AutoModel,AutoTokenizer\n",
        "device = 'cuda'\n",
        "PRE_TRAINED_MODEL_NAME = 'ai4bharat/indic-bert'\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40efbyr8S0sC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1614f816-f87a-49c6-d163-cb41f8d79494"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "MAX_LEN = 128\n",
        "train_data_loader = create_data_loader(train,tokenizer,MAX_LEN,BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(val,tokenizer,MAX_LEN,BATCH_SIZE)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdZHZ9UDTK1z"
      },
      "source": [
        "BERT_model = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOP_4eY031CX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class RFClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(RFClassifier, self).__init__()\n",
        "    self.auto = AutoModel.from_pretrained('ai4bharat/indic-bert')\n",
        "    self.lstm = nn.LSTM(768, 256, batch_first=True,bidirectional=True)\n",
        "    self.linear = nn.Linear(256*2, 128)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(0.4)\n",
        "    self.out = nn.Linear(128, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    sequence_output, pooled_output = self.auto(input_ids, \n",
        "               attention_mask=attention_mask)\n",
        "\n",
        "    # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
        "    lstm_output, (h,c) = self.lstm(sequence_output) ## extract the 1st token's embeddings\n",
        "    hidden = torch.cat((lstm_output[:,-1, :256],lstm_output[:,0, 256:]),dim=-1)\n",
        "    linear_output = self.linear(lstm_output[:,-1].view(-1,256*2)) ### assuming that you are only using the output of the last LSTM cell to perform classification\n",
        "\n",
        "    return linear_output"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Urr0ySUklT"
      },
      "source": [
        "model = RFClassifier(5)\n",
        "model = model.to(device)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5qaJSFdUtjo"
      },
      "source": [
        "EPOCHS = 10\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUMb1j_-VAPP"
      },
      "source": [
        "\n",
        "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        input_ids = data['input_ids'].to(device)\n",
        "        attention_mask = data['attention_mask'].to(device)\n",
        "        labels = data['label'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "            )\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs,labels)\n",
        "\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vXGF1gAa6pf"
      },
      "source": [
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"label\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      correct_predictions += torch.sum(preds == labels)\n",
        "      losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIJRHUwrgSDx"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb4NCM2lfQxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409e0c54-15da-46e0-85da-053b898caed9"
      },
      "source": [
        "from collections import defaultdict\n",
        "import torch\n",
        " \n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        " \n",
        " \n",
        "  start_time = time.time()\n",
        "  train_acc,train_loss = train_epoch(\n",
        "      model,\n",
        "      train_data_loader,\n",
        "      loss_fn,\n",
        "      optimizer,\n",
        "      device,\n",
        "      scheduler,\n",
        "      len(train)\n",
        "  )\n",
        "   \n",
        "  \n",
        "  val_acc,val_loss = eval_model(\n",
        "      model,\n",
        "      val_data_loader,\n",
        "      loss_fn,\n",
        "      device,\n",
        "      len(val)\n",
        "  )\n",
        "  \n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'Train Loss {train_loss} accuracy {train_acc}')\n",
        "  print(f'Val Loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(),'bert-base-multilingual-cased.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 3m 18s\n",
            "Train Loss 0.5345193509852696 accuracy 0.9050593379138039\n",
            "Val Loss 0.3147525228559971 accuracy 0.9310344827586207\n",
            "\n",
            "Epoch: 02 | Epoch Time: 3m 18s\n",
            "Train Loss 0.27625203358674955 accuracy 0.9367270455965022\n",
            "Val Loss 0.28904743031376884 accuracy 0.9335332333833083\n",
            "\n",
            "Epoch: 03 | Epoch Time: 3m 18s\n",
            "Train Loss 0.2326379958800451 accuracy 0.9472204871955028\n",
            "Val Loss 0.2656227633475311 accuracy 0.9395302348825587\n",
            "\n",
            "Epoch: 04 | Epoch Time: 3m 18s\n",
            "Train Loss 0.19690291501001683 accuracy 0.9557151780137414\n",
            "Val Loss 0.2604781146205607 accuracy 0.9435282358820589\n",
            "\n",
            "Epoch: 05 | Epoch Time: 3m 18s\n",
            "Train Loss 0.1602140445124633 accuracy 0.9630855715178014\n",
            "Val Loss 0.24340597821015214 accuracy 0.944527736131934\n",
            "\n",
            "Epoch: 06 | Epoch Time: 3m 18s\n",
            "Train Loss 0.11440265245322963 accuracy 0.9713928794503435\n",
            "Val Loss 0.24266938144518507 accuracy 0.9475262368815592\n",
            "\n",
            "Epoch: 07 | Epoch Time: 3m 18s\n",
            "Train Loss 0.08147055031490064 accuracy 0.9787632729544035\n",
            "Val Loss 0.24177248788524477 accuracy 0.952023988005997\n",
            "\n",
            "Epoch: 08 | Epoch Time: 3m 18s\n",
            "Train Loss 0.05973351758137018 accuracy 0.9846970643347908\n",
            "Val Loss 0.24936571846612626 accuracy 0.9495252373813093\n",
            "\n",
            "Epoch: 09 | Epoch Time: 3m 18s\n",
            "Train Loss 0.043973200762562614 accuracy 0.9891317926296065\n",
            "Val Loss 0.23807336906680748 accuracy 0.9575212393803099\n",
            "\n",
            "Epoch: 10 | Epoch Time: 3m 18s\n",
            "Train Loss 0.032595272758276665 accuracy 0.9941286695815116\n",
            "Val Loss 0.2446694573394895 accuracy 0.9600199900049975\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TM3YTH3l37C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "36284c56-2f38-483e-e061-1e05f08c8242"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "#plt.ylim([0, 1]);"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2bca296950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yV9fn/8deVRSAQCEmAAIEEwgh7hCF7iEVUrFiKVvQrP5VWUWtrbe3Ur63Vur5WQVu0KNaBFkddOAmCIsqQvRJCIAtICAnZ8/r9cR8gYIAAObkzrufjkQfn3Pd9zrlygPM+n3F/blFVjDHGmFP5uF2AMcaY+skCwhhjTLUsIIwxxlTLAsIYY0y1LCCMMcZUywLCGGNMtSwgTJMkIstE5H9q+9hzrGGCiKSeYf8/ROSPtf26xtSU2HkQpqEQkfwqd1sAJUCF5/5PVfWVuq/q/InIBOBlVe18gc+TDNysqp/VRl3GHOPndgHG1JSqtjx2+0wfiiLip6rldVlbQ2XvlTkT62IyDd6xrhoR+Y2IHABeEJEQEXlfRDJF5Ijnducqj1khIjd7bt8oIl+KyGOeY/eKyKXneWy0iKwUkTwR+UxEFojIy2ep/24ROSQiGSIyp8r2F0XkL57bYZ7fIUdEskVklYj4iMi/gS7AeyKSLyK/9hw/XUS2eY5fISKxVZ432fNebQYKROQeEXnzlJqeEpG/n8/fh2k8LCBMY9EBaAt0Bebi/Nt+wXO/C1AEzD/D40cAu4Aw4BHgXyIi53Hsq8C3QChwP3B9DepuDXQCbgIWiEhINcfdDaQC4UB74HeAqur1wH7gClVtqaqPiEhP4DXgLs/xH+IESECV57sWuAxoA7wMTBWRNuC0KoBrgJfOUrtp5CwgTGNRCdynqiWqWqSqh1X1TVUtVNU84EFg/Bkev09Vn1PVCmAxEIHzQVzjY0WkCzAM+JOqlqrql8C7Z6m7DHhAVctU9UMgH+h1muMigK6eY1fp6QcQZwEfqOqnqloGPAY0B0ZVOeYpVU3xvFcZwEpgpmffVCBLVdefpXbTyFlAmMYiU1WLj90RkRYi8k8R2SciR3E+ANuIiO9pHn/g2A1VLfTcbHmOx3YEsqtsA0g5S92HTxkDKDzN6z4KJAKfiEiSiNx7hufsCOyrUmOlp45OZ6hrMTDbc3s28O+z1G2aAAsI01ic+m36bpxv4iNUNRgY59l+um6j2pABtBWRFlW2RdbGE6tqnqrerardgOnAL0Vk8rHdpxyejtO1BoCn+ysSSKv6lKc85h1ggIj0Ay4HGtSMMOMdFhCmsWqFM+6QIyJtgfu8/YKqug9YB9wvIgEichFwRW08t4hcLiIxng/7XJzpvZWe3QeBblUOfwO4TEQmi4g/TliWAKvPUHsxsBTPGIqq7q+Nuk3DZgFhGqsncfrds4A1wEd19LrXARcBh4G/AK/jfDhfqB7AZzhjFF8Dz6hqvGffQ8AfPDOWfqWqu3C6iZ7G+f2vwBnELj3LaywG+mPdS8bDTpQzxotE5HVgp6p6vQVzoTyD7DuBDqp61O16jPusBWFMLRKRYSLS3XOOwlTgSpz+/XpNRHyAXwJLLBzMMXYmtTG1qwPwFs55EKnArar6nbslnZmIBOGMY+zDmeJqDGBdTMYYY07DupiMMcZUq9F0MYWFhWlUVJTbZRhjTIOyfv36LFUNr25fowmIqKgo1q1b53YZxhjToIjIvtPtsy4mY4wx1bKAMMYYUy0LCGOMMdVqNGMQ1SkrKyM1NZXi4uKzH2yahMDAQDp37oy/v7/bpRhT7zXqgEhNTaVVq1ZERUVx+mu/mKZCVTl8+DCpqalER0e7XY4x9V6j7mIqLi4mNDTUwsEAICKEhoZai9KYGmrUAQFYOJiT2L8HY2quUXcxGWNMY5ZTWMqn2w9SVqH8ZESXWn/+Rt+CcFNOTg7PPPPMeT122rRp5OTk1HJFxpiGLruglCXf7ueGRd8S95fPuGfpZpauP9uVbc+PtSC86FhA3Hbbbd/bV15ejp/f6d/+Dz/80JulnTdVRVXx8bHvFsbUlcy8Ej7edoBlWzNYk5RNRaXSpW0Lbh7bjWn9O9C/U2uvvK79L/eie++9lz179jBo0CDuueceVqxYwdixY5k+fTp9+vQB4Ic//CFDhw6lb9++LFy48Phjo6KiyMrKIjk5mdjYWG655Rb69u3LJZdcQlFR0fde67333mPEiBEMHjyYiy++mIMHDwKQn5/PnDlz6N+/PwMGDODNN98E4KOPPmLIkCEMHDiQyZOdSxvff//9PPbYY8efs1+/fiQnJ5OcnEyvXr244YYb6NevHykpKdx6663ExcXRt29f7rvvxLVw1q5dy6hRoxg4cCDDhw8nLy+PcePGsXHjxuPHjBkzhk2bNtXiO21M43PwaDGLVycz659fM/yvn/GHd7aSkVPMreO788GdY/jingnce2lvBnRu47WxtSbTgvjf97axPb12r4PSp2Mw913R97T7H374YbZu3Xr8w3HFihVs2LCBrVu3Hp9muWjRItq2bUtRURHDhg3j6quvJjQ09KTnSUhI4LXXXuO5557jxz/+MW+++SazZ88+6ZgxY8awZs0aRITnn3+eRx55hMcff5w///nPtG7dmi1btgBw5MgRMjMzueWWW1i5ciXR0dFkZ2ef9XdNSEhg8eLFjBw5EoAHH3yQtm3bUlFRweTJk9m8eTO9e/dm1qxZvP766wwbNoyjR4/SvHlzbrrpJl588UWefPJJdu/eTXFxMQMHDqz5G21ME5GWU8RHWw+wbEsG6/YdAaBn+5bcOakH0/pH0LN9yzqdaNFkAqK+GD58+Elz8J966inefvttAFJSUkhISPheQERHRzNo0CAAhg4dSnJy8veeNzU1lVmzZpGRkUFpaenx1/jss89YsmTJ8eNCQkJ47733GDdu3PFj2rZte9a6u3btejwcAN544w0WLlxIeXk5GRkZbN++HREhIiKCYcOGARAcHAzAzJkz+fOf/8yjjz7KokWLuPHGG8/6esY0FfsPF7JsawbLth5gY4oz7hgbEczdU3pyaf8OxLRr5VptTSYgzvRNvy4FBQUdv71ixQo+++wzvv76a1q0aMGECROqnaPfrFmz47d9fX2r7WK64447+OUvf8n06dNZsWIF999//znX5ufnR2Vl5fH7VWupWvfevXt57LHHWLt2LSEhIdx4441nPLegRYsWTJkyhf/+97+88cYbrF+//pxrM6Yx2ZtVwIdbMli2NYOtaU7PRv9Orfn11F5c2i+C6LCgszxD3WgyAeGGVq1akZeXd9r9ubm5hISE0KJFC3bu3MmaNWvO+7Vyc3Pp1KkTAIsXLz6+fcqUKSxYsIAnn3wScLqYRo4cyW233cbevXuPdzG1bduWqKgo3n//fQA2bNjA3r17q32to0ePEhQUROvWrTl48CDLli1jwoQJ9OrVi4yMDNauXcuwYcPIy8ujefPm+Pn5cfPNN3PFFVcwduxYQkJCzvv3NKahSjyUx4dbDvDhlgx2HnA+FwZ3acPvpvXm0n4RRLZt4XKF32cB4UWhoaGMHj2afv36cemll3LZZZedtH/q1Kn84x//IDY2ll69ep3UhXOu7r//fmbOnElISAiTJk06/uH+hz/8gXnz5tGvXz98fX257777mDFjBgsXLmTGjBlUVlbSrl07Pv30U66++mpeeukl+vbty4gRI+jZs2e1rzVw4EAGDx5M7969iYyMZPTo0QAEBATw+uuvc8cdd1BUVETz5s357LPPaNmyJUOHDiU4OJg5c+ac9+9oTEOiquw66ITCsi0ZJBzKRwTiuobwp8v7MLVfBzq2ae52mWfUaK5JHRcXp6deMGjHjh3Exsa6VJGpKj09nQkTJrBz507Xp8javwvjLarKtvSjzpjClgMkZRXgIzA8ui3T+kfwg74daB8c6HaZJxGR9aoaV90+a0EYr3vppZf4/e9/zxNPPOF6OBhT21SVzam5fOgJhf3Zhfj6CBd1C+WmsdFc0qcD4a2anf2J6iELCON1N9xwAzfccIPbZRhTa8oqKtmw7wifbj/Isq0HSMspws9HGB0TxryJ3ZnSpwNtgwLcLvOCWUAYY0wNZOWXsGJXJvG7DrFydyZ5xeUE+PowtkcYv5jSkymx7WndonFdZ8QCwhhjqlFZqWxJyyV+1yHidx5ic1ouqhDeqhmX9uvApN7tGB0TRqvAxhUKVVlAGGOMR25RGV8mZLF85yG+2H2IrPxSRGBQZBt+eXFPJvZuR5+IYHx8msay8RYQxpgmS1VJOJTP8p1OK2HdviNUVCqtm/szvmc4E3uHM75nu0YxnnA+LCDqmZYtW5Kfn096ejp33nknS5cu/d4xEyZM4LHHHiMurtqZaQA8+eSTzJ07lxYtnJNvpk2bxquvvkqbNm28VrsxDUFRaQWr92R5uo4ySctxViaIjQjmp+O6Mal3OwZFtsHP12bcWUDUUx07dqw2HGrqySefZPbs2ccDor4uH346tqy4qU37DxcSv+sQy3ce4uukw5SWV9IiwJfRMWHcPimGCb3CiWhdv09ac4P97/Oie++9lwULFhy/f2w57fz8fCZPnsyQIUPo378///3vf7/32OTkZPr16wdAUVER11xzDbGxsVx11VUnrcVU3bLbTz31FOnp6UycOJGJEycCJ5YPB3jiiSfo168f/fr1O74Ehy0rbhqT0vJKVidm8Zf3tzP58RWMezSe+97dxv7sQmaP6Mq/bxrOd3+awnM3xHHt8C4WDqfRdFoQy+6FA1tq9zk79IdLHz7t7lmzZnHXXXcxb948wFkB9eOPPyYwMJC3336b4OBgsrKyGDlyJNOnTz/tMr7PPvssLVq0YMeOHWzevJkhQ4Yc31fdstt33nknTzzxBPHx8YSFhZ30XOvXr+eFF17gm2++QVUZMWIE48ePJyQkxJYVNw3aoaPFx7uNvkzMIr/EmYY6oltbrhvRlYm929WbRfAaiqYTEC4YPHgwhw4dIj09nczMTEJCQoiMjKSsrIzf/e53rFy5Eh8fH9LS0jh48CAdOnSo9nlWrlzJnXfeCcCAAQMYMGDA8X3VLbtddf+pvvzyS6666qrjq7POmDGDVatWMX36dFtW3DQoFZXKxpQcVni6jrZ5rvcS0TqQKwZ2ZFLvdozqHkpQM/uYO19N5507wzd9b5o5cyZLly7lwIEDzJo1C4BXXnmFzMxM1q9fj7+/P1FRUWdcLvt0znXZ7bOxZcVNfVdRqaxMyOTdjems2HWII4Vl+AgM7RrCr6f2YmKvdvTu0KpOL6rTmNkYhJfNmjWLJUuWsHTpUmbOnAk4S3O3a9cOf39/4uPj2bdv3xmfY9y4cbz66qsAbN26lc2bNwPVL7t9zOmWGh87dizvvPMOhYWFFBQU8PbbbzN27Nga/z5nW1b8mGPLiq9cufL4yrLHupiioqLYsGEDcO7LigMnLSsOkJeXR3l5OQA333wzd955J8OGDbNlxRuRlOxCnvh0N2P+tpw5L6wlftchJvZqx1PXDua7P17Cf342itsmxBAbEWzhUIuaTgvCJX379iUvL49OnToREREBwHXXXccVV1xB//79iYuLo3fv3md8jltvvZU5c+YQGxtLbGwsQ4cOBU6/7DbA3LlzmTp1Kh07diQ+Pv749iFDhnDjjTcyfPhwwPlAHTx4cLXdSdWxZcVNXSkpr+DT7Qd5fW0KXyY6EyzG9gjnj5f34eLY9gT42fdbb7Plvk2jUpNlxe3fRf2260Aer69N4e3vUjlSWEanNs2ZGdeZmXGRdKrn109oiGy5b9Mk2LLiDVd+STnvb0pnydoUNqbk4O8rXNKnA7OGRTI6JgzfJrK0RX1jAWEaDVtWvGFRVTbsz+GNtSm8tzmdwtIKerRryR8ui+WqwZ0Ibdkwr6HQmDT6gFBVG7QyxzWWLtWG7HB+CW9/l8bra1NIOJRPiwBfrhjQkR8Pi2RIlzb2/7UeadQBERgYyOHDhwkNDbV/dAZV5fDhwwQG1q9LPjYFlZXKl4lZvL42hU+2H6CsQhncpQ0Pz+jP5QM70tLOVaiXvPq3IiJTgb8DvsDzqvrwKfu7AouAcCAbmK2qqZ59jwCX4UzF/RT4uZ7j17/OnTuTmppKZmbmBf8upnEIDAykc+fObpfRZKTlFPGfdSn8Z10qaTlFhLTw5/qRUcwaFkmvDq3cLs+chdcCQkR8gQXAFCAVWCsi76rq9iqHPQa8pKqLRWQS8BBwvYiMAkYDx04J/hIYD6w4lxr8/f2Pn8VrjKkbpeWVfLbjIEvWprAqwflyNiYmjN9O682UPu1p5ufrcoWmprzZghgOJKpqEoCILAGuBKoGRB/gl57b8cA7ntsKBAIBgAD+wEEv1mqMuUAJB53pqW99l0Z2QSkRrQO5Y1IPZg7tTGTbFm6XZ86DNwOiE5BS5X4qMOKUYzYBM3C6oa4CWolIqKp+LSLxQAZOQMxX1R1erNUYcx4KSsr5YHMGr69LYf2+I/j5CFP6tGfWsEjG9gi36akNnNsjQ78C5ovIjcBKIA2oEJEYIBY41ln8qYiMVdVVVR8sInOBuQBdunSps6KNacpUlU2puby+dj/vbkynoLSC7uFB/H5aLFcN6USYTU9tNLwZEGlAZJX7nT3bjlPVdJwWBCLSErhaVXNE5BZgjarme/YtAy4CVp3y+IXAQnDOpPbS72GMwWktvLEuhSXfprDrYB7N/X25bEAE1wyLZGjXEJsp2Ah5MyDWAj1EJBonGK4BflL1ABEJA7JVtRL4Lc6MJoD9wC0i8hBOF9N44Ekv1mqMOY3cojIWr05m0Vd7ySksY2Dn1vz1qv5cMTCCVoH+bpdnvMhrAaGq5SJyO/AxzjTXRaq6TUQeANap6rvABOAhEVGcLqZ5nocvBSYBW3AGrD9S1fe8Vasx5vsO55ew6Ku9vLR6H3kl5Vwc2455E2MY3MVWyW0qGvVifcaYc3fwaDHPrUzilW/2U1xewbR+Edw2sTt9O7Z2uzTjBbZYnzHmrFKPFPKPL/bwxrpUKiqVKwd15LYJMcS0a+l2acYlFhDGNHFJmfk8u2IPb3+Xhgj8aGgkt47vTpdQO3ehqbOAMKaJ2nngKAvi9/DB5nT8fX2YPbIrPx3fjYjWds0F47CAMKaJ2Zyaw/zliXyy/SBBAb7MHdedm8ZEE97Kzl8wJ7OAMKaJWJeczdPLE/lidybBgX78fHIP5oyOok2LALdLM/WUBYQxjZiqsnrPYZ5ensCapGxCgwL4zdTezB7Zxc5hMGdlAWFMI6SqLN95iKeXJ7IxJYf2wc340+V9uHZ4F5oH2GqqpmYsIIxpRCorlY+2HeDp5YnsyDhK55DmPHhVP340tLMts23OmQWEMY1AeUUl725K55kVe0g8lE+38CAenzmQ6YM64u/r43Z5poGygDCmASspr+CtDWk8u2IP+7ML6d2hFfN/MphL+0XYUtvmgllAGNMAFZdVsOTb/fxzZRIZucUM7NyaP10ex+TYdraqqqk1FhDGNCD5JeW8vGYfz6/aS1Z+CcOj2/LIjwYwJibMgsHUOgsIYxqA3MIyXvQsuZ1bVMbYHmHcPnEwI7qFul2aacQsIIypx4rLKlj01V6eXbGHvOJypvRpz+0TYxgY2cbt0kwTYAFhTD1UUam8uSGV//t0Nxm5xVwc2467L+lFbESw26WZJsQCwph6RFVZsSuTh5ftZNfBPAZGtuHJWYOsK8m4wgLCmHpic2oOD324k6+TDhMV2oJnrhvCpf062OCzcY0FhDEu23+4kEc/2cV7m9IJDQrggSv7cu3wLnaCm3GdBYQxLskuKOXp5Qm8vGYffj4+3DEphrnjutkieqbesIAwpo4VlTozk/6xYg8FpeXMGhbJXRf3pH1woNulGXMSCwhj6khFpfLm+lSe+HQ3B44Wc3Fse34ztRc92rdyuzRjqmUBYYyXnTozaVBkG566djDDo9u6XZoxZ2QBYYwXbUrJ4aFlO1iTlG0zk0yDYwFhjBfsO1zAox/v4v3NGTYzyTRYFhDG1KLsglKe+jyBV75xZibdOSmGW2xmkmmgLCCMqQXfn5nUhV9c3IN2NjPJNGAWEMZcgGMzkx7/dBcHj5YwpY8zMymmnc1MMg2fBYQx50FVid91iIeX7WT3wXwGd2nD/J8MYViUzUwyjYcFhDHnaFNKDn/9cAff7M0mOiyIZ68bwlSbmWQaIQsIY2po3+ECHvl4Fx9sziCsZQB/vrIv19jMJNOIWUAYcxaH80t4enniiZlJk3swd1w3Wjaz/z6mcbN/4cacRm5RGYtXJ7NwZRJFZRXOmkmTbWaSaTosIIw5RXZBKYu+3Mvi1cnklZTbzCTTZFlAGONx6Ggxz61K4uU1+ykur2Bavwhum9idvh1bu12aMa6wgDBNXuqRQv75RRKvr0uholK5cmBHbpvY3VoMpsmzgDBN1t6sAp5dkchbG9IQgR8N7czPxnena2iQ26UZUy94NSBEZCrwd8AXeF5VHz5lf1dgERAOZAOzVTXVs68L8DwQCSgwTVWTvVmvaRp2HchjQXwi729Ox9/Xh9kjuzJ3XDc6tmnudmnG1CteCwgR8QUWAFOAVGCtiLyrqturHPYY8JKqLhaRScBDwPWefS8BD6rqpyLSEqj0Vq2madiSmsv8+AQ+3naQoABfbhnXjZvHdCO8VTO3SzOmXvJmC2I4kKiqSQAisgS4EqgaEH2AX3puxwPveI7tA/ip6qcAqprvxTpNI7cuOZunlyfyxe5MggP9uHNyD+aMiiIkKMDt0ow5dwWHIXOn52eX82erDjBjYa2/lDcDohOQUuV+KjDilGM2ATNwuqGuAlqJSCjQE8gRkbeAaOAz4F5Vraj6YBGZC8wF6NKlizd+B9NAqSqr9xzm6eUJrEnKpm1QAL+e2ovrR3a1pbdN/acK+YdODoFjfxZmnTguoCWE94KW7b1ShtuD1L8C5ovIjcBKIA2owKlrLDAY2A+8DtwI/Kvqg1V1IbAQIC4uTuuqaFN/qSrLdx5ifnwi3+3PoX1wM/54eR+uHR5JiwC3/7kbcwpVOJpefRAU55w4rllraNcbek+D8N5OKIT3huBO4MU1wLz5PyYNZ4D5mM6ebcepajpOCwLPOMPVqpojIqnAxirdU+8AIzklIIw5prJS+WjbAeYvT2R7xlE6hzTnLz/sx4+GdibQ39ft8kxTV1kJuSnfD4HMXVCad+K45m2hXSz0m3FyELRs79UgOJ2zBoSIXAF8oKrnOki8FughItE4wXAN8JNTnjsMyPY8929xZjQde2wbEQlX1UxgErDuHF/fNAHlFZW8tzmdBfF7SDyUT7ewIB6bOZArB3W0RfRM3ausgCPJ3x8jyEqAssITx7Vs73z4D7r2RAiE94agMNdKr05NWhCzgCdF5E1gkarurMkTq2q5iNwOfIwzzXWRqm4TkQeAdar6LjABeEhEFKeLaZ7nsRUi8ivgc3HWUF4PPHeOv5tpxErKK3hrQxrPrtjD/uxCendoxdPXDmZa/wh8fWzZbVMHinMhacXJrYGsBKgoOXFMcCcnAIaOPhEEYT2hRcO4boionr3rXkSCgWuBOTjnJLwAvKaqeWd8YB2Ki4vTdeuskdHYFZdVsOTb/fxzZRIZucUM7Nya2yf1YHLvdvhYMJi6UFoI3/4TvnzyxDhBmy4ndwkdC4LAYHdrrQERWa+qcdXtq9EYhKoeFZGlQHPgLpwZR/eIyFOq+nTtlWpM9fJLynl5zT6eX7WXrPwShke15W9XD2BsjzC7UI+pG+WlsGExrHwU8g9Cj0tgzC8gYiAENM6z72syBjEdp+UQg3Py2nBVPSQiLXDOabCAMF6TW1jGi6uTWfTVXnKLyhjbI4zbJw5mRLdQt0szTUVlBWz5D8T/FXL2QZdRMHMxdL3I7cq8riYtiKuB/1PVlVU3qmqhiNzknbJMU5ddUMrzq5J46et95JeUc3Fse26fFMOgyDZul2aaClXY+T4s/4szxtBhAFz3JsRMdmVGkRtqEhD3AxnH7ohIc6C9qiar6ufeKsw0TcVlFbzwVTLPxCeSX1rOtP4RzJsQQ5+O9b8v1zQie+Lh8wcgfQOE9nBaDLHTwadpzYyrSUD8BxhV5X6FZ9swr1RkmqTKSuW9zek88tEu0nKKmNy7Hfde2pse7W3JbVOHUtbC8gdg70poHQlXLoAB14Bv0zzJsia/tZ+qlh67o6qlImKL2JhaszY5m7+8v51Nqbn0iQjm0R8NYFRM/ZoPbhq5g9ucrqRdH0JQOEz9G8TNAb+mvZBjTQIiU0Sme85bQESuBLLO8hhjzio5q4CHl+3ko20H6BAcyGMzBzJjcCebrmrqTnYSxD/kDEI3C4ZJf4QRP4NmLd2urF6oSUD8DHhFROYDgrMA3w1erco0akcKSnlqeQIvr9mHv68Pd0/pyc1ju9E8wJbEMHXkaDp88Qh892/w8Ycxd8GoOxvMCWx15awBoap7gJGetZJs6W1z3krKK3hp9T6eXp5Afkk5s4ZF8ospPWnXKtDt0kxTUXAYvvo/+PY5Z/rq0Dkw7lfOctnme2o08iIilwF9gcBjJyWp6gNerMs0IqrKh1sO8LePdrI/u5DxPcP53bRYenWwAWhTR0ry4OtnYPXTUFbgDDxP+A2ERLldWb1WkxPl/gG0ACbiXAL0R8C3Xq7LNBLr9x3hwQ+2s2F/Dr07tOKl/zeccT3D3S7LnK/yEvANaDjnAZQVw7p/warHofAwxF4BE//gLJ1tzqomLYhRqjpARDar6v+KyOPAMm8XZhq2lOxCHv5oJx9sziC8VTP+dnV/fjQ00hbSa2hU4cBm2P0J7P4I0tZD8zanrDvk+bNVRP0Jjooy2PiKM85wNA26TYTJf4ROQ92urEGpSUAUe/4sFJGOwGEgwnslmYYst7CM+fEJLF69Dx8fuHNyD346rhtBzZrmPPIGqbQAkr6AhI+dYMhLBwQ6DXHWHio64qxcuv2/UPTiicc1C/aERZUF68J7QXDnujvBrLIStr3lLIuRvQc6D4Or/gHR4+rm9RuZmvyvfU9E2gCPAhtwVnO1pbfNSUrLK3nlm338/fMEcovK+NGQztx9SS86tCYl98cAABjRSURBVLYB6AbhyD5I8LQS9q5ylqwOaAUxk6DHD6DHFGjZ7uTHqEJB1vevfbD7E/ju5RPH+QdBeM/vtzradAWfWpq5pgq7P4blf4aDW6FdX7h2CfScWn9aNQ3QGZf7FhEfYKSqrvbcbwYEqmpuHdVXY7bctztUlY+3HeRvH+1kb1YBo2NC+d20WPp2bO12aeZMKsoh9VvnQ3X3x5C5w9netrvzodrzB9DlIvA7z3NiC7Orv3paXvqJY/wCIazH95fJDok+tzOXk790lsVI+cZ57KQ/QN8ZTW5ZjPN1puW+z3o9CBH5TlUHe6WyWmQBUfc2peTw4Ic7+HZvNjHtWvL7abFM6BVuy2/XV4XZkPi503WU8KlzLQMfP+g62gmEHj+AsBjv1lCcC5m7T2l17ILc/SeO8Q2A0Jjvj3G07X5yYKV/5wTDnuXO+Mf438Dg2eDr793foZG50OtBfC4iVwNvaU2uLmQavdQjhTz68S7+uzGd0KAA/vLDflwzLBI/u8Rn/aIKh3Z4xhI+dr5ha6WzlETvy5xQ6Daxbi9qE9gaIoc5P1WV5EPW7pNbG+kbYds7OL3agPhCaHcnMCrKYfcy5xrOl/wFht0M/s3r7vdoImrSgsgDgoBynAFrAVRV69XymtaC8L6jxWU8u2IP//pyLwLcPDaan43vTqtA+8ZWb5QVQ/IqZyxh9ycnvplHDHRaCD2nQsfBDaf7pazIuYzn8eDwhEfREScULprXIK7aVp9dUAtCVe1spiauvKKS177dz5OfJXC4oJQZgztx9w960amNfWOrF46mnxhL2PsFlBWCfwundTDuV86Vz4Ib6MRD/+YQMcD5MXWuJifKVTs/7NQLCJnGR1VZvvMQf/1wB3syCxgR3ZYXL+tD/842AO2qygpI2+C0EhI+hgNbnO1tujp98D1/AF3HgL/NIDMXpiZjEPdUuR0IDAfWA5O8UpGpF7am5fLgBzv4Oukw3cKCWHj9UKb0aW8D0G4pyoGkeKeVkPApFGY5ffJdRsKUB5zuo/BeNqXT1KqadDFdUfW+iEQCT3qtIuOqQ3nF/G3ZLt76LpU2zf353+l9+cmILvjbAHTdKToCGZshYyNkbHJ+Dic6+5qHQMwUp5UQM9m5b4yXnM/pralAbG0XYty3bEsGv3t7CwUlFcwd243bJsbQurkNQHtVwWFPEFQJgyPJJ/a3jnQGmAdcA9FjnTODa+vkMmPOoiZjEE9zfJ4ZPsAgnDOqTSORW1TG/767jbe+S2NA59Y88eOBxLSzuQm1Lu/gyUGQvhGOpp7YHxINEYNgyP9Ax0HQYSAEhbpXr2nyatKCqDp3tBx4TVW/8lI9po59mZDFPUs3cSivhLsu7sG8iTHWnXShVJ2ZRcfCIN3zZ/4BzwHinAjWZaQTBBEDocMAZxE8Y+qRmgTEUqBYVSsARMRXRFqoaqF3SzPeVFRawd8+2smLq5PpHh7E27eNYkBn+4A6Z6qQs+/kVkHGJmcQGUB8IKwXdJtQJQz6QzNroZn6r0ZnUgMXA8euJNcc+AQY5a2ijHdtSsnhF29sJCmzgDmjo/jN1N4E+lu/9llVVsKRvU7LIL1KV1FxjrPfxw/CY6HXVKerKGIgtO8HAS3crduY81STgAiseplRVc0XEfsX3wCVVVTy9PJEFsQn0r5VM169eQSjYsLcLqt+qKxw1gkqOuJ84BflOPeLcyAr0QmCA5uh5KhzvG8AtOsDfX/oBEHEIOe+nXtgGpGaBESBiAxR1Q0AIjIUKPJuWaa2JR7K4xevb2JLWi4zhnTi/ul9CW5sS2SUl3g+5HO+/yF/0rac7x9Xmnf65/ULdLqFBvz4RBiE9z7/lU6NaSBqEhB3Af8REc9VQ+gAzPJqVabWVFYqL6xO5m8f7aRlMz/+MXsIU/s1gGUXCg5D1q7Tf6BXt638LN9b/IOcxeKat4HANtAmEgL7n7zt2J9VtwWFn9vy08Y0EjU5UW6tiPQGenk27VLVMu+WZWpDWk4Rv3pjE18nHebi2Hb8dUZ/2rWqp10gJfmwb7WzllDSF3BwS/XHNQv2fJC3dv4Mi3E+zKt+uDcP+f62wNb2jd+Yc1ST8yDmAa+o6lbP/RARuVZVn/F6dea8qCpvbkjjf9/dRqUqj1w9gJlxnevXMhnlpZC2zgmDvV9A6lqoLHf69iNHOBd96TjYWc656oe8nSRmTJ2pSbv5FlVdcOyOqh4RkVsAC4h6KCu/hN+9tYVPth9keHRbHp85kMi29WBOQWWlcynIpBVOIOz7GsoKAHGCYNQdED3eOTfA1vU3pl6oSUD4iogcu1iQiPgC1lavhz7dfpDfvrWZo0Xl/H5aLDeNicbHx6VWgypkJ53oMkpeBYWHnX1hPWHQT6DbeIgaY+sJGVNP1SQgPgJeF5F/eu7/FFjmvZLMucorLuPP72/njXWp9IkI5pWbB9GrgwsnYuUdhL0rT7QSclOc7a06OtckiB7vhEJwx7qvzRhzzmoSEL8B5gI/89zfjDOT6axEZCrwd8AXeF5VHz5lf1dgERAOZAOzVTW1yv5gYDvwjqreXpPXbGrWJB3m7jc2kZFbxO0TY7hzcg8C/OpoqYziXEj+6kQr4diF7wNbQ/Q4GP1z5wzi0BhbhtqYBqgms5gqReQboDvwYyAMePNsj/N0RS0ApuCsALtWRN5V1e1VDnsMeElVF4vIJOAh4Poq+/8M2IWJqlFcVsFjH+/iX1/tJSo0iKW3jmJIFy931ZQVQ+q3JwaW0zaAVjjnCXS5CAbOcloJEQNtMNmYRuC0ASEiPYFrPT9ZwOsAqjqxhs89HEhU1STP8y0BrsRpERzTB/il53Y88E6V1x8KtMfp4qr2eqlN1da0XH7x+kYSDuVz/ciu/HZab1oEeGGefmWFs6zEsUDYvwbKi50L1XQaAmN+4bQQIoeDX7Paf31jjKvO9KmyE1gFXK6qiQAi8otzeO5OQEqV+6nAiFOO2QTMwOmGugpoJSKhwBHgcWA2zjpQ1RKRuTjdX3Tp0uUcSmuYyisqeXbFHv7+eQKhLQNY/P+GM75neO2+SN4B2PGeM46QvMrpRgJnjaGhc5wxhK6j7ULxxjQBZwqIGcA1QLyIfAQswTmTujb9CpgvIjfidCWlARXAbcCHqpp6prn7qroQWAgQFxenpz2wEUjKzOeXb2xiY0oOVw7qyAPT+9G6RS0tlVFZAYmfwfrFznWOtQJad4HYKyB6gjOe0Kp97byWMabBOG1AqOo7wDsiEoTTNXQX0E5EngXeVtVPzvLcaUBklfudPduqvkY6ThAhIi2Bq1U1R0QuAsaKyG1ASyBARPJV9d5z+/UaPlXl32v28dcPdxDo78v8nwzm8gG1NAsoZz9897LzczTNWVJi1O0w6DpnKqoNLBvTpNVkkLoAeBV4VURCgJk4M5vOFhBrgR4iEo0TDNcAP6l6gIiEAdmqWgn8FmdGE6p6XZVjbgTimmI4ZOQW8eulm1mVkMWEXuH87eoBtA++wKUyykth9zKntbBnubMtZjJMfQh6XmrLURhjjjunkU1VPYLTpbOwBseWi8jtwMc401wXqeo2EXkAWKeq7wITgIdERHG6mOadY/2Nkqry7qZ0/vjOVsoqlAev6sdPhne5sKUyshJhw2LY9BoUZEJwJxj/axg8G9o0/vEbY8y5E88J0g1eXFycrlu37uwH1nNHCkr5wztb+WBLBkO7hvD4zIFEhQWd35OVFTkDzusXw74vndlHvS6FITdAzMU2FdUYg4isV9VqZ4raGsb1SPzOQ/z6zc3kFJby66m9+Om47viez1IZB7c5obD5dWcp7JAomPwnZ2yhVY3OcTTGGAuI+mJVQiZzXlxL7w6tWDxnOH06nuM00pJ82Pqm042Utt5ZFTX2ChjyPxA1Fnzq6OxqY0yjYQFRD6gqf/8sgY6tA3ln3uiaXx9a1TmbecNiJxxK8yGsF/zgrzDgGggK9W7hxphGzQKiHvhmbzbr9h3hgSv71iwcio7A5v84wXBwK/g1h34znNZC5HCbnmqMqRUWEPXA/OWJhLVsxo/jIk9/kKpzxbUNL8H2d5wlLyIGwmVPQP8fOQvkGWNMLbKAcNnGlBy+TMzit5f2rr71UJAFG191guFwgnPJzUHXOTOROg6q+4KNMU2GBYTL5i9PpHVzf64b2fXExspKSIp3upB2fgiVZc5lOMc8A31/CAHnOe3VGGPOgQWEi3YeOMpnOw5y18U9aNnMD46mO8tebPg35O53rsc8fC4MuR7axbpdrjGmibGAcENRDmTtZv37n3B/s+1cl1YE/5dw4gps0ePg4vucaaq2jLYxxiUWEN5UmA2ZOz0/u078mZcBwHVAmU8z/It6QpeR0G4O9L0K2nZzt25jjMEC4sKpOmsbnRoCmTud7cf4B0F4T+cCO+G9WLS7Ga8mNee1e2YR3rqFW9UbY8xpWUDUlKrzzb+6ICg6cuK4ZsEQ3gt6/gDCe3t+ekFw5+NnM6ceKeSvH65g9siuFg7GmHrLAuJUlZVwNLVKCBwLgl1QcvTEcYFtnIHjPleeCIHw3tAq4qwnqi1cmYQIzB1nXUnGmPrLAqIoB9a/UCUQdkNZwYn9QeHOB/+AH58cBEHh53XG8qG8YpasTWHG4M50bNO8Fn8RY4ypXRYQIvDZ/c43//BezpTSYyEQ1qvW1zP616q9lFdUcuuE7rX6vMYYU9ssIAJbw73762SpiiMFpfx7zT6uGNjx/K/xYIwxdcTWgIY6W8fohdXJFJZWcNuEmDp5PWOMuRAWEHUkr7iMF7/ayyV92tOrQyu3yzHGmLOygKgjL6/Zz9Hicm6fZK0HY0zDYAFRB4rLKvjXl0mM7RHGgM5t3C7HGGNqxAKiDiz5dj9Z+aXcMamH26UYY0yNWUB4WWl5Jf9cmcTwqLYMj27rdjnGGFNjFhBe9taGVDJyi5lnYw/GmAbGAsKLyisqefaLPfTv1JpxPcLcLscYY86JBYQXfbAlg32HC5k3MQY5j2U5jDHGTRYQXlJZqSyIT6Rn+5Zc0qe92+UYY8w5s4Dwkk+2H2T3wXzmTYzBx8daD8aYhscCwgtUndZD19AWXNY/wu1yjDHmvFhAeMHKhCy2pOVy6/ju+PnaW2yMaZjs08sLFixPJKJ1IDOGdHa7FGOMOW8WELXs273ZfJuczdxx3Qjws7fXGNNw2SdYLZsfn0hoUADXDOvidinGGHNBLCBq0aaUHFbuzuTmsd1oHuDrdjnGGHNBLCBq0YL4RIID/Zg90loPxpiGzwKiluw6kMcn2w9y4+hoWgX6u12OMcZcMAuIWvLMikRaBPgyZ1SU26UYY0yt8GpAiMhUEdklIokicm81+7uKyOcisllEVohIZ8/2QSLytYhs8+yb5c06L1RyVgHvbUpn9siuhAQFuF2OMcbUCq8FhIj4AguAS4E+wLUi0ueUwx4DXlLVAcADwEOe7YXADaraF5gKPCki9fZSbP/4Yg9+vj7cPCba7VKMMabWeLMFMRxIVNUkVS0FlgBXnnJMH2C553b8sf2qultVEzy304FDQLgXaz1v6TlFvLkhlWuGRdIuONDtcowxptZ4MyA6ASlV7qd6tlW1CZjhuX0V0EpEQqseICLDgQBgz6kvICJzRWSdiKzLzMystcLPxcKVSajCT8d3d+X1jTHGW9wepP4VMF5EvgPGA2lAxbGdIhIB/BuYo6qVpz5YVReqapyqxoWH130DIzOvhNe+3c9VgzvRqU3zOn99Y4zxJj8vPncaEFnlfmfPtuM83UczAESkJXC1quZ47gcDHwC/V9U1XqzzvP3ry72UVVRy6wRrPRhjGh9vtiDWAj1EJFpEAoBrgHerHiAiYSJyrIbfAos82wOAt3EGsJd6scbzllNYyr+/TmZa/wi6hbd0uxxjjKl1XgsIVS0Hbgc+BnYAb6jqNhF5QESmew6bAOwSkd1Ae+BBz/YfA+OAG0Vko+dnkLdqPR8vrk6moLSCeRNj3C7FGGO8QlTV7RpqRVxcnK5bt65OXiu/pJzRDy9nWFRbnv+fuDp5TWOM8QYRWa+q1X6QuT1I3SC9smYfuUVl3D7JWg/GmMbLAuIcFZdV8NyqvYyJCWNQZL09d88YYy6YBcQ5emNdCln5JTb2YIxp9CwgzkFpeSX//CKJoV1DGNmtrdvlGGOMV1lAnIN3vksjLaeI2yfFICJul2OMMV5lAVFDFZXKs1/soV+nYCb0rJfLQhljTK2ygKihD7ZksDergHkTrPVgjGkaLCBqoLJSeSY+kZh2LflB3w5ul2OMMXXCAqIGPt95iJ0H8rhtQnd8fKz1YIxpGiwgzkJVmb88gci2zZk+sKPb5RhjTJ2xgDiLLxOz2JSay63jY/DztbfLGNN02CfeWcxfnkiH4ECuHnrqtY6MMaZxs4A4g3XJ2XyzN5tbxnWjmZ+v2+UYY0ydsoA4g/nxibQNCuDa4ZFnP9gYYxoZC4jT2JqWy4pdmdw0JpoWAd688J4xxtRPFhCnMX95Iq0C/bj+oq5ul2KMMa6wgKhGwsE8Ptp2gBtHRREc6O92OcYY4woLiGo8s2IPzf19mTM62u1SjDHGNRYQp9h/uJB3N6Vz3YgutA0KcLscY4xxjQXEKZ79Yg++ItwyrpvbpRhjjKssIKrIyC1i6foUZsZ1pn1woNvlGGOMqywgqli4MolKhZ+N7+52KcYY4zoLCI+s/BJe+3Y/PxzUici2LdwuxxhjXGcB4bHoy72UlFdy20RrPRhjDFhAAJBbVMa/v97HtH4RdA9v6XY5xhhTL1hAAC+tTiavpNxaD8YYU0WTD4iCknL+9dVeJvVuR9+Ord0uxxhj6o0mvwpdfkk5o7qHctMYO+/BGGOqavIB0T44kGeuG+p2GcYYU+80+S4mY4wx1bOAMMYYUy0LCGOMMdWygDDGGFMtCwhjjDHVsoAwxhhTLQsIY4wx1bKAMMYYUy1RVbdrqBUikgnsu4CnCAOyaqmchs7ei5PZ+3Eyez9OaAzvRVdVDa9uR6MJiAslIutUNc7tOuoDey9OZu/Hyez9OKGxvxfWxWSMMaZaFhDGGGOqZQFxwkK3C6hH7L04mb0fJ7P344RG/V7YGIQxxphqWQvCGGNMtSwgjDHGVKvJB4SITBWRXSKSKCL3ul2Pm0QkUkTiRWS7iGwTkZ+7XZPbRMRXRL4TkffdrsVtItJGRJaKyE4R2SEiF7ldk5tE5Bee/ydbReQ1EQl0u6ba1qQDQkR8gQXApUAf4FoR6eNuVa4qB+5W1T7ASGBeE38/AH4O7HC7iHri78BHqtobGEgTfl9EpBNwJxCnqv0AX+Aad6uqfU06IIDhQKKqJqlqKbAEuNLlmlyjqhmqusFzOw/nA6CTu1W5R0Q6A5cBz7tdi9tEpDUwDvgXgKqWqmqOu1W5zg9oLiJ+QAsg3eV6al1TD4hOQEqV+6k04Q/EqkQkChgMfONuJa56Evg1UOl2IfVANJAJvODpcnteRILcLsotqpoGPAbsBzKAXFX9xN2qal9TDwhTDRFpCbwJ3KWqR92uxw0icjlwSFXXu11LPeEHDAGeVdXBQAHQZMfsRCQEp7chGugIBInIbHerqn1NPSDSgMgq9zt7tjVZIuKPEw6vqOpbbtfjotHAdBFJxul6nCQiL7tbkqtSgVRVPdaiXIoTGE3VxcBeVc1U1TLgLWCUyzXVuqYeEGuBHiISLSIBOINM77pck2tERHD6mHeo6hNu1+MmVf2tqnZW1SicfxfLVbXRfUOsKVU9AKSISC/PpsnAdhdLctt+YKSItPD8v5lMIxy093O7ADeparmI3A58jDMLYZGqbnO5LDeNBq4HtojIRs+236nqhy7WZOqPO4BXPF+mkoA5LtfjGlX9RkSWAhtwZv99RyNcdsOW2jDGGFOtpt7FZIwx5jQsIIwxxlTLAsIYY0y1LCCMMcZUywLCGGNMtSwgjDkHIlIhIhur/NTa2cQiEiUiW2vr+Yy5UE36PAhjzkORqg5yuwhj6oK1IIypBSKSLCKPiMgWEflWRGI826NEZLmIbBaRz0Wki2d7exF5W0Q2eX6OLdPgKyLPea4z8ImINHftlzJNngWEMeem+SldTLOq7MtV1f7AfJyVYAGeBhar6gDgFeApz/angC9UdSDOmkbHzuDvASxQ1b5ADnC1l38fY07LzqQ25hyISL6qtqxmezIwSVWTPAseHlDVUBHJAiJUtcyzPUNVw0QkE+isqiVVniMK+FRVe3ju/wbwV9W/eP83M+b7rAVhTO3R09w+FyVVbldg44TGRRYQxtSeWVX+/NpzezUnLkV5HbDKc/tz4FY4ft3r1nVVpDE1Zd9OjDk3zausdAvONZqPTXUNEZHNOK2Aaz3b7sC5Cts9OFdkO7YC6s+BhSJyE05L4VacK5MZU2/YGIQxtcAzBhGnqllu12JMbbEuJmOMMdWyFoQxxphqWQvCGGNMtSwgjDHGVMsCwhhjTLUsIIwxxlTLAsIYY0y1/j+eyNv6fDeMfQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCB1-ymUoWtz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbfd8be9-ac5f-4e17-90c3-b48abe5b85d1"
      },
      "source": [
        "val_acc, _ = eval_model(\n",
        "  model,\n",
        "  val_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(val) #Change it to test when you have the test results\n",
        ")\n",
        "val_acc.item()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9600199900049975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAKW4Hz6obOV"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  sentence = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      texts = d[\"text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"label\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      sentence.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(labels)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return sentence, predictions, prediction_probs, real_values"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyNIoCR3oqKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e7c254-c677-49eb-8b4b-fc544d20500e"
      },
      "source": [
        "\n",
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  val_data_loader\n",
        ")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne7Nu8KIasmB"
      },
      "source": [
        "class_name=['Not_offensive',\n",
        "'not-Kannada',\n",
        "'Offensive_Targeted_Insult_Individual',\n",
        "'Offensive_Targeted_Insult_Group',          \n",
        "'Offensive_Untargetede',                    \n",
        "'Offensive_Targeted_Insult_Other']"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLJOJO0Eorvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd366c6-8b5e-4384-ca7d-2a2d17e2c7c7"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test, y_pred,zero_division=0, digits=4))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9663    0.9898    0.9779      1765\n",
            "           1     0.9167    0.4783    0.6286        23\n",
            "           2     0.7222    0.4815    0.5778        27\n",
            "           3     0.7222    0.4483    0.5532        29\n",
            "           4     0.9448    0.8726    0.9073       157\n",
            "\n",
            "    accuracy                         0.9600      2001\n",
            "   macro avg     0.8544    0.6541    0.7289      2001\n",
            "weighted avg     0.9572    0.9600    0.9568      2001\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_REU26jAOW4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}