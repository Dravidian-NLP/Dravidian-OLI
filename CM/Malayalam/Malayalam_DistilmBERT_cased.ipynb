{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Malayalam DistilmBERT cased",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adeepH/DravidianOffensive/blob/main/CM/Malayalam/Malayalam_DistilmBERT_cased.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp9ne18LI0ZD",
        "outputId": "46770398-a34c-4cd1-b103-aa74e1f71108"
      },
      "source": [
        "!pip install transformers==3.3.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3.3.1 in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (0.8.1rc2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (20.9)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (0.1.95)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.1) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGoQZFFYJlu8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "ugWqH7iskbgF",
        "outputId": "5d3c5aa9-d9be-4427-c1fc-23a4b4a71b70"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "train=pd.read_csv('/content/mal_full_offensive_train.tsv', header=None, names=['tweets','label'], sep=\"\\t\")\n",
        "train['labels']=LabelEncoder().fit_transform(train['label'])\n",
        "train=train.drop(columns='label')\n",
        "train"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്ത...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ഈ ഓണം ഏട്ടനും പിള്ളേർക്ക് ഉള്ളതാണ് എന്ന് ഉള്ളവ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sushin syam  Shaiju khalid  Midhun manual</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J A K E S.   B EJ O Y !!!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16005</th>\n",
              "      <td>കട്ട ലാലേട്ടൻ ഫാൻസിന് ദൈവത്തെ ഓർത്ത് അമിത പ്രത...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16006</th>\n",
              "      <td>ente mammookka ningal puliyalla oru simhama......</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16007</th>\n",
              "      <td>Lucifer mass dialogues Ellam onnu comment chey...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16008</th>\n",
              "      <td>Like from Madurai (Tamil nadu) ....</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16009</th>\n",
              "      <td>അടിമകൾ ആയി ജീവിച്ചു മാറിക്കയല്ല ചാവേറായി ചാവാറ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16010 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweets  labels\n",
              "0      പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്ത...       0\n",
              "1      ഈ ഓണം ഏട്ടനും പിള്ളേർക്ക് ഉള്ളതാണ് എന്ന് ഉള്ളവ...       0\n",
              "2      ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്...       0\n",
              "3              Sushin syam  Shaiju khalid  Midhun manual       0\n",
              "4                              J A K E S.   B EJ O Y !!!       0\n",
              "...                                                  ...     ...\n",
              "16005  കട്ട ലാലേട്ടൻ ഫാൻസിന് ദൈവത്തെ ഓർത്ത് അമിത പ്രത...       0\n",
              "16006  ente mammookka ningal puliyalla oru simhama......       0\n",
              "16007  Lucifer mass dialogues Ellam onnu comment chey...       0\n",
              "16008                Like from Madurai (Tamil nadu) ....       4\n",
              "16009  അടിമകൾ ആയി ജീവിച്ചു മാറിക്കയല്ല ചാവേറായി ചാവാറ...       0\n",
              "\n",
              "[16010 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "Whp4CHwJOr8H",
        "outputId": "757a5093-4492-441a-fc7b-e5af9f09ea06"
      },
      "source": [
        "val = pd.read_csv('/content/mal_full_offensive_test_with_labels.csv', delimiter='\\t', names=['tweets','label','nan'])\n",
        "val = val.drop(columns=['nan'])\n",
        "val['labels']=LabelEncoder().fit_transform(val['label'])\n",
        "val=val.drop(columns='label')\n",
        "val"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>അപ്പൊ ഇതൊരൊന്നൊരാ മൊതലാണല്ലേ  Suraj ആണ് നടൻ ന്...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>എന്ത് ഊള എഡിറ്റിംഗ് ആടോ ഇത് ഒരുമാതിരി vivo vid...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fefka ee padam release cheyyan samadhicho?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>അആഹാ.. സംഗീതം ജെക്‌സ് ബിജോയ് ആണ് അപ്പൊ പൊട്ടലു...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ravile thane views likes ethra ayyi enn nokan ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>Swargatthil ninnu purathaakkappetta daivatthin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Ivide Palakkad Jayettan Fans club nnu ashamsak...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>Koora padam urappa kandal aryam.. Hello</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2001 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 tweets  labels\n",
              "0     അപ്പൊ ഇതൊരൊന്നൊരാ മൊതലാണല്ലേ  Suraj ആണ് നടൻ ന്...       0\n",
              "1     എന്ത് ഊള എഡിറ്റിംഗ് ആടോ ഇത് ഒരുമാതിരി vivo vid...       0\n",
              "2            Fefka ee padam release cheyyan samadhicho?       0\n",
              "3     അആഹാ.. സംഗീതം ജെക്‌സ് ബിജോയ് ആണ് അപ്പൊ പൊട്ടലു...       0\n",
              "4     Ravile thane views likes ethra ayyi enn nokan ...       0\n",
              "...                                                 ...     ...\n",
              "1996  Swargatthil ninnu purathaakkappetta daivatthin...       0\n",
              "1997  Ivide Palakkad Jayettan Fans club nnu ashamsak...       0\n",
              "1998      ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും       0\n",
              "1999  കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...       0\n",
              "2000            Koora padam urappa kandal aryam.. Hello       0\n",
              "\n",
              "[2001 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMd3ZHtlPpLv"
      },
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class RFDataset(Dataset):\n",
        "  def __init__(self,tweets,labels,tokenizer,max_len):\n",
        "    self.tweets = tweets\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.tweets)\n",
        "  \n",
        "  def __getitem__(self,item):\n",
        "    tweets = str(self.tweets[item])\n",
        "    labels = self.labels[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        tweets,\n",
        "        add_special_tokens=True,\n",
        "        max_length = self.max_len,\n",
        "        return_token_type_ids = False,\n",
        "        padding = 'max_length',\n",
        "        return_attention_mask= True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'tweets' : tweets,\n",
        "        'input_ids' : encoding['input_ids'].flatten(),\n",
        "        'attention_mask' : encoding['attention_mask'].flatten(),\n",
        "        'labels' : torch.tensor(labels,dtype=torch.long)\n",
        "\n",
        "    }"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDdVdA1bQlUF",
        "outputId": "b991665c-ac96-4442-9367-d12ffcd411d6"
      },
      "source": [
        " \n",
        "print('Training set size:',train.shape)\n",
        "#Uncomment the next line when we have the test data\n",
        "#print('Testing set size:',test.shape)\n",
        "print('validation set size:',val.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size: (16010, 2)\n",
            "validation set size: (2001, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFA6pybHQwOX",
        "outputId": "060b95ff-c935-4043-e9f0-b3755045ec94"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                  np.unique(train.labels.values),\n",
        "                                                  train.labels.values)\n",
        "class_weights"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.22624179, 22.87142857, 13.39748954, 16.76439791,  2.48795649])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrS3mf4RQyy9"
      },
      "source": [
        "def create_data_loader(df,tokenizer,max_len,batch_size):\n",
        "  ds = RFDataset(\n",
        "      tweets = df.tweets.to_numpy(),\n",
        "      labels = df.labels.to_numpy(),\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(ds,\n",
        "                    batch_size = batch_size,\n",
        "                    shuffle = True,\n",
        "                    num_workers=4)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5HC7hmTQ1zg"
      },
      "source": [
        "from transformers import XLNetTokenizer,XLNetModel,AdamW,get_linear_schedule_with_warmup,AutoModel,AutoTokenizer\n",
        "device = 'cuda'\n",
        "PRE_TRAINED_MODEL_NAME = 'distilbert-base-multilingual-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_c7oQlUQ4ED",
        "outputId": "19a0ffbf-0dea-47c9-a4a3-318d5b9f8cc4"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 512\n",
        "train_data_loader = create_data_loader(train,tokenizer,MAX_LEN,BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(val,tokenizer,MAX_LEN,BATCH_SIZE)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkIQTq3Q6-b"
      },
      "source": [
        "BERT_model = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELD76HMVQ9HQ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class DistillBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistillBERTClass, self).__init__()\n",
        "        self.l1 = AutoModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 6)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzOmQqNyRAqg"
      },
      "source": [
        "\n",
        "model = DistillBERTClass()\n",
        "model = model.to(device)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxxmEAKvRC5H"
      },
      "source": [
        "EPOCHS = 5\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x444fs7R0oz"
      },
      "source": [
        "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        input_ids = data['input_ids'].to(device)\n",
        "        attention_mask = data['attention_mask'].to(device)\n",
        "        labels = data['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "            )\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs,labels)\n",
        "\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGTlOJP3R2rX"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"labels\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      correct_predictions += torch.sum(preds == labels)\n",
        "      losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvBZLbZAR4wN"
      },
      "source": [
        "\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN5SVoUVR6kL",
        "outputId": "da79fbf2-18e4-4a0e-a15a-d94a85e125f4"
      },
      "source": [
        "from collections import defaultdict\n",
        "import torch\n",
        " \n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        " \n",
        " \n",
        "  start_time = time.time()\n",
        "  train_acc,train_loss = train_epoch(\n",
        "      model,\n",
        "      train_data_loader,\n",
        "      loss_fn,\n",
        "      optimizer,\n",
        "      device,\n",
        "      scheduler,\n",
        "      len(train)\n",
        "  )\n",
        "   \n",
        " \n",
        "  val_acc,val_loss = eval_model(\n",
        "      model,\n",
        "      val_data_loader,\n",
        "      loss_fn,\n",
        "      device,\n",
        "      len(val)\n",
        "  )\n",
        "\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'Train Loss {train_loss} accuracy {train_acc}')\n",
        "  print(f'Val Loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if train_acc > best_accuracy:\n",
        "     \n",
        "    best_accuracy = train_acc\n",
        "torch.save(model.state_dict(),'distilbert-base-multilingual-cased.bin')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 13m 40s\n",
            "Train Loss 0.305843856169858 accuracy 0.9239225484072454\n",
            "Val Loss 0.27528070512833813 accuracy 0.9325337331334332\n",
            "\n",
            "Epoch: 02 | Epoch Time: 13m 43s\n",
            "Train Loss 0.21188354024758468 accuracy 0.9496564647095566\n",
            "Val Loss 0.23861974980016903 accuracy 0.9430284857571214\n",
            "\n",
            "Epoch: 03 | Epoch Time: 13m 43s\n",
            "Train Loss 0.16219134830156123 accuracy 0.9600249843847595\n",
            "Val Loss 0.23812516658411673 accuracy 0.9470264867566217\n",
            "\n",
            "Epoch: 04 | Epoch Time: 13m 42s\n",
            "Train Loss 0.1225792491235412 accuracy 0.9711430356027483\n",
            "Val Loss 0.25842153828402625 accuracy 0.953023488255872\n",
            "\n",
            "Epoch: 05 | Epoch Time: 13m 43s\n",
            "Train Loss 0.09530592496952528 accuracy 0.9751405371642723\n",
            "Val Loss 0.227774942389852 accuracy 0.952023988005997\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pXpyt4kPR8Qo",
        "outputId": "d20ea135-1201-44e8-949a-643b9848f5e7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4jnJ_DeVChr",
        "outputId": "7fc95e18-2965-44f3-9825-899ecf68eb3a"
      },
      "source": [
        "val_acc, _ = eval_model(\n",
        "  model,\n",
        "  val_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(val) #Change it to test when you have the test results\n",
        ")\n",
        "val_acc.item()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.952023988005997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrOtx2a1VFPV"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  sentence = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      tweets = d[\"tweets\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"labels\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      sentence.extend(tweets)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(labels)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return sentence, predictions, prediction_probs, real_values"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A6ySmh7VNeo",
        "outputId": "c90cdc5f-9d48-4c5c-cfe5-8863a0074a26"
      },
      "source": [
        "\n",
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  val_data_loader\n",
        ")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AbMa4soViJ-",
        "outputId": "47fa0eb3-be97-40b8-dd98-3206c7f258ca"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test, y_pred,zero_division=0, digits=4))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9704    0.9847    0.9775      1765\n",
            "           1     0.0000    0.0000    0.0000        23\n",
            "           2     0.5385    0.5185    0.5283        27\n",
            "           3     0.4815    0.4483    0.4643        29\n",
            "           4     0.9032    0.8917    0.8974       157\n",
            "\n",
            "    accuracy                         0.9520      2001\n",
            "   macro avg     0.5787    0.5686    0.5735      2001\n",
            "weighted avg     0.9411    0.9520    0.9465      2001\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaYOjpfbO84z"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    }
  ]
}